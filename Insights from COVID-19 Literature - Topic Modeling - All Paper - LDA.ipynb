{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pprint\n",
    "# import ijson\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import fnmatch\n",
    "import glob\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for dirname, _, filenames in os.walk('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# for filename in fnmatch.filter(filenames, '*.txt'):\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "input = Path('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge')\n",
    "output = Path('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sources_metadata = pd.read_csv(input / 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44220, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44220 entries, 0 to 44219\n",
      "Data columns (total 15 columns):\n",
      "sha                            28462 non-null object\n",
      "source_x                       44220 non-null object\n",
      "title                          43996 non-null object\n",
      "doi                            40750 non-null object\n",
      "pmcid                          23319 non-null object\n",
      "pubmed_id                      22943 non-null float64\n",
      "license                        44220 non-null object\n",
      "abstract                       35806 non-null object\n",
      "publish_time                   34197 non-null object\n",
      "authors                        41074 non-null object\n",
      "journal                        33173 non-null object\n",
      "Microsoft Academic Paper ID    964 non-null float64\n",
      "WHO #Covidence                 1767 non-null object\n",
      "has_full_text                  44220 non-null bool\n",
      "full_text_file                 32829 non-null object\n",
      "dtypes: bool(1), float64(2), object(12)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df_all_sources_metadata.shape)\n",
    "df_all_sources_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>full_text_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Intrauterine virus infections and congenital h...</td>\n",
       "      <td>10.1016/0002-8703(72)90077-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4361535.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract The etiologic basis for the vast majo...</td>\n",
       "      <td>1972-12-31</td>\n",
       "      <td>Overall, James C.</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Coronaviruses in Balkan nephritis</td>\n",
       "      <td>10.1016/0002-8703(80)90355-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6243850.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Cigarette smoking and coronary heart disease: ...</td>\n",
       "      <td>10.1016/0002-8703(80)90356-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7355701.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Friedman, Gary D</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aecbc613ebdab36753235197ffb4f35734b5ca63</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Clinical and immunologic studies in identical ...</td>\n",
       "      <td>10.1016/0002-9343(73)90176-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4579077.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Middle-aged female identical twins, o...</td>\n",
       "      <td>1973-08-31</td>\n",
       "      <td>Brunner, Carolyn M.; Horwitz, David A.; Shann,...</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Epidemiology of community-acquired respiratory...</td>\n",
       "      <td>10.1016/0002-9343(85)90361-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4014285.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Upper respiratory tract infections ar...</td>\n",
       "      <td>1985-06-28</td>\n",
       "      <td>Garibaldi, Richard A.</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sha  source_x  \\\n",
       "0                                       NaN  Elsevier   \n",
       "1                                       NaN  Elsevier   \n",
       "2                                       NaN  Elsevier   \n",
       "3  aecbc613ebdab36753235197ffb4f35734b5ca63  Elsevier   \n",
       "4                                       NaN  Elsevier   \n",
       "\n",
       "                                               title  \\\n",
       "0  Intrauterine virus infections and congenital h...   \n",
       "1                  Coronaviruses in Balkan nephritis   \n",
       "2  Cigarette smoking and coronary heart disease: ...   \n",
       "3  Clinical and immunologic studies in identical ...   \n",
       "4  Epidemiology of community-acquired respiratory...   \n",
       "\n",
       "                            doi pmcid  pubmed_id    license  \\\n",
       "0  10.1016/0002-8703(72)90077-4   NaN  4361535.0  els-covid   \n",
       "1  10.1016/0002-8703(80)90355-5   NaN  6243850.0  els-covid   \n",
       "2  10.1016/0002-8703(80)90356-7   NaN  7355701.0  els-covid   \n",
       "3  10.1016/0002-9343(73)90176-9   NaN  4579077.0  els-covid   \n",
       "4  10.1016/0002-9343(85)90361-4   NaN  4014285.0  els-covid   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  Abstract The etiologic basis for the vast majo...   1972-12-31   \n",
       "1                                                NaN   1980-03-31   \n",
       "2                                                NaN   1980-03-31   \n",
       "3  Abstract Middle-aged female identical twins, o...   1973-08-31   \n",
       "4  Abstract Upper respiratory tract infections ar...   1985-06-28   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                  Overall, James C.   \n",
       "1  Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...   \n",
       "2                                   Friedman, Gary D   \n",
       "3  Brunner, Carolyn M.; Horwitz, David A.; Shann,...   \n",
       "4                              Garibaldi, Richard A.   \n",
       "\n",
       "                            journal  Microsoft Academic Paper ID  \\\n",
       "0            American Heart Journal                          NaN   \n",
       "1            American Heart Journal                          NaN   \n",
       "2            American Heart Journal                          NaN   \n",
       "3  The American Journal of Medicine                          NaN   \n",
       "4  The American Journal of Medicine                          NaN   \n",
       "\n",
       "  WHO #Covidence  has_full_text  full_text_file  \n",
       "0            NaN          False  custom_license  \n",
       "1            NaN          False  custom_license  \n",
       "2            NaN          False  custom_license  \n",
       "3            NaN           True  custom_license  \n",
       "4            NaN          False  custom_license  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code for reading in the JSON file is taken from ...\n",
    "\n",
    "https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 708 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29315"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_json = glob.glob(f'{input}/**/*.json', recursive=True)\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0015023cc06b5362d332b3baf348d11567ca2fbb: word count: 194 22 Text word count: 5168 23 24 25 author/funder. All rights reserved. No reuse allowed without permission. Abstract 27 The positive stranded RNA genomes of picornaviruses comprise a si... VP3, and VP0 (which is further processed to VP2 and VP4 during virus assembly) (6). The P2 64 and P3 regions encode the non-structural proteins 2B and 2C and 3A, 3B (1-3) (VPg), 3C pro and 4 structura...\n"
     ]
    }
   ],
   "source": [
    "class FileReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path) as file:\n",
    "            content = json.load(file)\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            # Abstract\n",
    "            for entry in content['abstract']:\n",
    "                self.abstract.append(entry['text'])\n",
    "            # Body text\n",
    "            for entry in content['body_text']:\n",
    "                self.body_text.append(entry['text'])\n",
    "            self.abstract = '\\n'.join(self.abstract)\n",
    "            self.body_text = '\\n'.join(self.body_text)\n",
    "            # Extend Here\n",
    "            #\n",
    "            #\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
    "first_row = FileReader(all_json[0])\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 0 of 29315\n",
      "Processing index: 2931 of 29315\n",
      "Processing index: 5862 of 29315\n",
      "Processing index: 8793 of 29315\n",
      "Processing index: 11724 of 29315\n",
      "Processing index: 14655 of 29315\n",
      "Processing index: 17586 of 29315\n",
      "Processing index: 20517 of 29315\n",
      "Processing index: 23448 of 29315\n",
      "Processing index: 26379 of 29315\n",
      "Processing index: 29310 of 29315\n",
      "Wall time: 2min 44s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>Nipah Virus (NiV) came into limelight recently...</td>\n",
       "      <td>Nipah is an infectious negative-sense single-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>Background: A novel coronavirus (2019-nCoV) em...</td>\n",
       "      <td>In December 2019, a cluster of patients with p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  Infectious bronchitis (IB) causes significant ...   \n",
       "3  Nipah Virus (NiV) came into limelight recently...   \n",
       "4  Background: A novel coronavirus (2019-nCoV) em...   \n",
       "\n",
       "                                           body_text  \n",
       "0  VP3, and VP0 (which is further processed to VP...  \n",
       "1  The 2019-nCoV epidemic has spread across China...  \n",
       "2  Infectious bronchitis (IB), which is caused by...  \n",
       "3  Nipah is an infectious negative-sense single-s...  \n",
       "4  In December 2019, a cluster of patients with p...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\n",
    "for idx, entry in enumerate(all_json):\n",
    "    if idx % (len(all_json) // 10) == 0:\n",
    "        print(f'Processing index: {idx} of {len(all_json)}')\n",
    "    content = FileReader(entry)\n",
    "    dict_['paper_id'].append(content.paper_id)\n",
    "    dict_['abstract'].append(content.abstract)\n",
    "    dict_['body_text'].append(content.body_text)\n",
    "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text'])\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>Nipah Virus (NiV) came into limelight recently...</td>\n",
       "      <td>Nipah is an infectious negative-sense single-s...</td>\n",
       "      <td>326</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>Background: A novel coronavirus (2019-nCoV) em...</td>\n",
       "      <td>In December 2019, a cluster of patients with p...</td>\n",
       "      <td>22</td>\n",
       "      <td>4642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  Infectious bronchitis (IB) causes significant ...   \n",
       "3  Nipah Virus (NiV) came into limelight recently...   \n",
       "4  Background: A novel coronavirus (2019-nCoV) em...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  VP3, and VP0 (which is further processed to VP...                  241   \n",
       "1  The 2019-nCoV epidemic has spread across China...                    0   \n",
       "2  Infectious bronchitis (IB), which is caused by...                 1647   \n",
       "3  Nipah is an infectious negative-sense single-s...                  326   \n",
       "4  In December 2019, a cluster of patients with p...                   22   \n",
       "\n",
       "   body_word_count  \n",
       "0             1728  \n",
       "1              755  \n",
       "2             4003  \n",
       "3             2399  \n",
       "4             4642  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_covid['abstract_word_count'] = df_covid['abstract'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid['body_word_count'] = df_covid['body_text'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 text word count: 5168 23 24...</td>\n",
       "      <td>vp3, and vp0 (which is further processed to vp...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>the 2019-ncov epidemic has spread across china...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>infectious bronchitis (ib) causes significant ...</td>\n",
       "      <td>infectious bronchitis (ib), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>nipah virus (niv) came into limelight recently...</td>\n",
       "      <td>nipah is an infectious negative-sense single-s...</td>\n",
       "      <td>326</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>background: a novel coronavirus (2019-ncov) em...</td>\n",
       "      <td>in december 2019, a cluster of patients with p...</td>\n",
       "      <td>22</td>\n",
       "      <td>4642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  infectious bronchitis (ib) causes significant ...   \n",
       "3  nipah virus (niv) came into limelight recently...   \n",
       "4  background: a novel coronavirus (2019-ncov) em...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  vp3, and vp0 (which is further processed to vp...                  241   \n",
       "1  the 2019-ncov epidemic has spread across china...                    0   \n",
       "2  infectious bronchitis (ib), which is caused by...                 1647   \n",
       "3  nipah is an infectious negative-sense single-s...                  326   \n",
       "4  in december 2019, a cluster of patients with p...                   22   \n",
       "\n",
       "   body_word_count  \n",
       "0             1728  \n",
       "1              755  \n",
       "2             4003  \n",
       "3             2399  \n",
       "4             4642  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: x.lower())\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: x.lower())\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <td>29315</td>\n",
       "      <td>29315</td>\n",
       "      <td>b3935c8b90d9ca6671636eaae86eab9cb0295fe8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>29315</td>\n",
       "      <td>21049</td>\n",
       "      <td></td>\n",
       "      <td>8051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_text</th>\n",
       "      <td>29315</td>\n",
       "      <td>29117</td>\n",
       "      <td>in previous reports, workers have characterize...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_word_count</th>\n",
       "      <td>29315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.501</td>\n",
       "      <td>175.353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>240</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_word_count</th>\n",
       "      <td>29315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4802.29</td>\n",
       "      <td>7322.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2444</td>\n",
       "      <td>3730</td>\n",
       "      <td>5509.5</td>\n",
       "      <td>260378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique  \\\n",
       "paper_id             29315  29315   \n",
       "abstract             29315  21049   \n",
       "body_text            29315  29117   \n",
       "abstract_word_count  29315    NaN   \n",
       "body_word_count      29315    NaN   \n",
       "\n",
       "                                                                   top  freq  \\\n",
       "paper_id                      b3935c8b90d9ca6671636eaae86eab9cb0295fe8     1   \n",
       "abstract                                                                8051   \n",
       "body_text            in previous reports, workers have characterize...     4   \n",
       "abstract_word_count                                                NaN   NaN   \n",
       "body_word_count                                                    NaN   NaN   \n",
       "\n",
       "                        mean      std  min   25%   50%     75%     max  \n",
       "paper_id                 NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "abstract                 NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "body_text                NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "abstract_word_count  164.501  175.353    0     0   161     240    4767  \n",
       "body_word_count      4802.29  7322.71    1  2444  3730  5509.5  260378  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>b3935c8b90d9ca6671636eaae86eab9cb0295fe8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>29117</td>\n",
       "      <td>21044</td>\n",
       "      <td></td>\n",
       "      <td>8004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_text</th>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>it has been recognized for decades that the co...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_word_count</th>\n",
       "      <td>29117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.504</td>\n",
       "      <td>175.637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_word_count</th>\n",
       "      <td>29117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4811.94</td>\n",
       "      <td>7344.37</td>\n",
       "      <td>1</td>\n",
       "      <td>2450</td>\n",
       "      <td>3733</td>\n",
       "      <td>5513</td>\n",
       "      <td>260378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique  \\\n",
       "paper_id             29117  29117   \n",
       "abstract             29117  21044   \n",
       "body_text            29117  29117   \n",
       "abstract_word_count  29117    NaN   \n",
       "body_word_count      29117    NaN   \n",
       "\n",
       "                                                                   top  freq  \\\n",
       "paper_id                      b3935c8b90d9ca6671636eaae86eab9cb0295fe8     1   \n",
       "abstract                                                                8004   \n",
       "body_text            it has been recognized for decades that the co...     1   \n",
       "abstract_word_count                                                NaN   NaN   \n",
       "body_word_count                                                    NaN   NaN   \n",
       "\n",
       "                        mean      std  min   25%   50%   75%     max  \n",
       "paper_id                 NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "abstract                 NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "body_text                NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "abstract_word_count  164.504  175.637    0     0   160   240    4767  \n",
       "body_word_count      4811.94  7344.37    1  2450  3733  5513  260378  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.drop_duplicates(['body_text'], inplace=True)\n",
    "df_covid.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwrods from STOPWORDS:  190\n",
      "Number of stopwrods from stopwords.words('english'):  179\n",
      "Number of stopwrods from custom_stopwords:  263\n",
      "['else', 're', 'http', 'and', 'will', 'needn', 'at', \"here's\", \"isn't\", \"let's\", 'theirs', \"it's\", \"that's\", 'under', 'com', 'also', 'below', 'such', 'after', \"i've\", 'as', 'being', 'be', 'so', 'doesn', 'these', \"needn't\", \"he'd\", 'because', 'now', 'ought', 'nor', 'than', 'our', 'haven', 'wasn', \"he's\", 'aren', \"haven't\", 'ourselves', \"won't\", \"when's\", \"they'll\", 'since', 'it', 'about', \"we're\", 'ever', 'been', 'which', 'until', 'before', 'very', 'with', 'when', 'from', 'hers', 'again', \"she'd\", 'while', 'above', 'both', \"should've\", 'what', 'shan', 't', 'up', 'here', 'did', 'during', 'how', 'her', 'had', 'or', 'same', 'its', \"doesn't\", 'no', 'y', \"hasn't\", \"she'll\", 'over', \"weren't\", 'you', 'should', 'this', 'if', 'just', \"aren't\", 'do', 'hadn', \"mustn't\", 'some', 'yours', 'but', 'by', 'don', 'between', 'myself', 'further', \"we'll\", 'ours', 'are', \"i'm\", 'herself', 'll', \"couldn't\", 'they', 'shouldn', 'shall', 'that', 'an', 'on', 'too', \"we've\", 'am', 'of', \"you'll\", 'does', 'them', 'doing', \"mightn't\", 'a', 'd', \"they've\", 'once', \"you're\", 'me', 'the', 'out', 'all', 'however', 'like', 'any', \"wasn't\", 'have', 'she', 'mustn', 'few', \"shan't\", \"she's\", 'can', \"where's\", \"why's\", 'each', 'get', 'he', 'their', 'couldn', 'mightn', \"i'll\", \"they'd\", \"you'd\", 'to', 've', 'www', 'r', 'hasn', 'down', 'through', 'cannot', 'most', \"wouldn't\", 'who', 'was', \"who's\", \"we'd\", 'won', \"hadn't\", 'having', 'yourselves', \"don't\", 'ain', 'my', 'whom', 'off', 'more', 'him', \"they're\", 'not', 's', 'didn', 'yourself', \"that'll\", 'i', 'for', 'ma', 'were', 'itself', 'himself', 'has', \"there's\", \"can't\", \"i'd\", \"what's\", 'there', 'in', 'wouldn', 'then', 'would', 'o', 'we', 'your', 'isn', \"how's\", 'why', 'is', 'could', 'only', 'otherwise', 'weren', 'themselves', \"he'll\", \"shouldn't\", 'k', 'where', 'm', 'other', 'those', \"didn't\", 'his', 'against', \"you've\", 'own', 'into', 'q', 'license', 'preprint', 'copyright', 'http', 'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', 'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da', 'dell', 'non', 'si']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"Number of stopwrods from STOPWORDS: \", len(STOPWORDS))\n",
    "print(\"Number of stopwrods from stopwords.words('english'): \", len(stopwords.words('english')))\n",
    "other_stopwords = ['q', 'license', 'preprint', 'copyright', 'http', 'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', 'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si']\n",
    "custom_stopwords = []\n",
    "custom_stopwords = list(set(stopwords.words('english') + list(STOPWORDS))) + other_stopwords\n",
    "\n",
    "print(\"Number of stopwrods from custom_stopwords: \", len(custom_stopwords))\n",
    "print(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_stopword_tokens(tokens, tolower=False):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    remove_punc = [word for word in tokens if word not in string.punctuation]\n",
    "    if tolower:\n",
    "        return [word.lower() for word in remove_punc if word.lower() not in custom_stopwords]\n",
    "    else:\n",
    "        return [word for word in remove_punc if word not in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_stopword_text(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    remove_punc = [word for word in text if word not in string.punctuation]\n",
    "    remove_punc = ''.join(remove_punc)\n",
    "    return [word.lower() for word in remove_punc.split() if word.lower() not in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_text(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        remove_punc = [word for word in tokens if word not in string.punctuation]\n",
    "        remove_stopwords = [word.lower() for word in remove_punc if word.lower() not in custom_stopwords]\n",
    "        more_than_three = [w for w in remove_stopwords if len(w)>3]\n",
    "        lem = [lemmatizer.lemmatize(w) for w in more_than_three]\n",
    "        return ' '.join(lem)\n",
    "\n",
    "# cleaned_text = clean_the_text(\"my name is TRIVIKRAM, and I am first born in my fam don't process processing patients\")\n",
    "# print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_for_nlp = df_covid.copy()\n",
    "df_covid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_covid_for_nlp['cleaned_text'] = df_covid_for_nlp['body_text'].apply(lambda x: clean_the_text(x))\n",
    "# print(cleaned_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    processed virus assembly region encode non-str...\n",
       "1    2019-ncov epidemic spread across china country...\n",
       "2    infectious bronchitis caused infectious bronch...\n",
       "3    nipah infectious negative-sense single-strande...\n",
       "4    december 2019 cluster patient pneumonia unknow...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp_10K = df_covid_for_nlp.head(10000).copy()\n",
    "df_covid_for_nlp_10K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix_countvectorizer = count_vect.fit_transform(df_covid_for_nlp_10K['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x110226 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7517951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=50, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=50, random_state=42, n_jobs=-1)\n",
    "LDA.fit(doc_term_matrix_countvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poult\n",
      "vaccinepreventable\n",
      "ctni\n",
      "heading\n",
      "strewn\n",
      "denner\n",
      "okayama\n",
      "3050\n",
      "ipilimumab\n",
      "2673\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106325,  96144,  76161,  86412, 105990,  53255, 106475,  23334,\n",
       "        63943,  82451], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viral\n",
      "structure\n",
      "pcv2\n",
      "replication\n",
      "vesicle\n",
      "infected\n",
      "virus\n",
      "cell\n",
      "membrane\n",
      "prrsv\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['viral', 'structure', 'pcv2', 'replication', 'vesicle', 'infected', 'virus', 'cell', 'membrane', 'prrsv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['stem', 'ribosome', 'frame', 'trna', 'frameshifting', 'sequence', 'translation', 'site', 'mrna', 'codon']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['cell', 'genome', 'interaction', 'ifitm3', 'host', 'replication', 'domain', 'viral', 'virus', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['method', 'positive', 'probe', 'reaction', 'pcr', 'rt', 'detection', 'primer', 'assay', 'sample']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['host', 'immune', 'activation', 'ifn', 'type', 'protein', 'response', 'viral', 'virus', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['protein', 'vector', 'human', 'immune', 'virus', 'antigen', 'antibody', 'response', 'cell', 'vaccine']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['anti', 'immune', 'level', 'macrophage', 'response', 'cytokine', 'expression', 'mouse', 'il', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['coronaviruses', 'hcov', 'coronavirus', 'camel', 'bat', 'virus', 'human', 'sars', 'mers', 'cov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['protein', 'acid', 'amino', 'genome', 'codon', 'isolates', 'mutation', 'sequence', 'gene', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['ebov', 'effect', 'inhibitor', 'viral', 'treated', 'protein', 'virus', 'entry', 'infected', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #10:\n",
      "['sample', 'case', 'clinical', 'pneumonia', 'pathogen', 'viral', 'patient', 'virus', 'child', 'respiratory']\n",
      "\n",
      "\n",
      "Top 10 words for topic #11:\n",
      "['sequencing', 'hadv', 'community', 'microbiota', 'microbial', 'specie', 'pathogen', 'bacteria', 'bacterial', 'sample']\n",
      "\n",
      "\n",
      "Top 10 words for topic #12:\n",
      "['replication', 'control', 'viral', 'culture', 'level', 'gene', 'virus', 'infected', 'expression', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #13:\n",
      "['mouse', 'cell', 'ifn', 'gondii', 'gene', 'stat1', 'expression', 'infected', 'cov', 'sars']\n",
      "\n",
      "\n",
      "Top 10 words for topic #14:\n",
      "['day', 'allergic', 'clinical', 'symptom', 'effect', 'subject', 'trial', 'group', 'asthma', 'treatment']\n",
      "\n",
      "\n",
      "Top 10 words for topic #15:\n",
      "['control', 'intestinal', 'astrocyte', 'calf', 'microglia', 'animal', 'neuron', 'group', 'mouse', 'brain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #16:\n",
      "['2013', '2011', 'treatment', 'target', '2012', 'antiviral', 'compound', 'activity', 'effect', 'drug']\n",
      "\n",
      "\n",
      "Top 10 words for topic #17:\n",
      "['virus', 'aptamers', 'pdcov', 'farm', 'porcine', 'swine', 'tgev', 'piglet', 'pig', 'pedv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #18:\n",
      "['compared', 'immune', 'control', 'challenge', 'level', 'response', 'vaccinated', 'vaccine', 'vaccination', 'group']\n",
      "\n",
      "\n",
      "Top 10 words for topic #19:\n",
      "['cc', '1101', 'doi', 'funder', 'org', '10', 'reviewed', 'author', 'peer', 'holder']\n",
      "\n",
      "\n",
      "Top 10 words for topic #20:\n",
      "['formation', 'pathway', 'viral', 'replication', 'lipid', 'membrane', 'stress', 'cell', 'protein', 'autophagy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #21:\n",
      "['rna', 'ifit1', 'stable', 'yeast', 'cell', 'mrna', 'expression', 'strain', 'reference', 'gene']\n",
      "\n",
      "\n",
      "Top 10 words for topic #22:\n",
      "['expression', 'network', 'lncrnas', 'function', 'peptide', 'mass', 'sample', 'identified', 'ms', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #23:\n",
      "['farm', 'wild', 'transmission', 'population', 'disease', 'pathogen', 'human', 'host', 'specie', 'animal']\n",
      "\n",
      "\n",
      "Top 10 words for topic #24:\n",
      "['level', 'associated', 'identified', 'expressed', 'pathway', 'response', 'transcript', 'table', 'expression', 'gene']\n",
      "\n",
      "\n",
      "Top 10 words for topic #25:\n",
      "['mortality', 'associated', 'level', 'blood', 'treatment', 'group', 'clinical', 'severe', 'disease', 'patient']\n",
      "\n",
      "\n",
      "Top 10 words for topic #26:\n",
      "['ncov', '2019', 'level', '5p', 'target', 'expression', 'cell', 'mirna', 'mirnas', 'mir']\n",
      "\n",
      "\n",
      "Top 10 words for topic #27:\n",
      "['group', 'reported', 'year', 'medical', 'risk', 'health', 'participant', 'care', 'patient', 'hospital']\n",
      "\n",
      "\n",
      "Top 10 words for topic #28:\n",
      "['treatment', 'level', 'anti', 'induced', 'expression', 'effect', 'tumor', 'activity', 'cancer', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #29:\n",
      "['solution', 'detection', 'phage', 'image', 'sample', 'method', 'temperature', 'concentration', 'surface', 'particle']\n",
      "\n",
      "\n",
      "Top 10 words for topic #30:\n",
      "['virus', 'domain', 'transfected', 'viral', 'expression', 'plasmid', 'binding', 'mutant', 'cell', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #31:\n",
      "['genetic', 'population', 'sequence', 'position', 'allele', 'rabv', 'strain', 'rabies', 'rvfv', 'variant']\n",
      "\n",
      "\n",
      "Top 10 words for topic #32:\n",
      "['patient', 'year', 'surveillance', '2009', 'respiratory', 'case', 'pandemic', 'h1n1', 'virus', 'influenza']\n",
      "\n",
      "\n",
      "Top 10 words for topic #33:\n",
      "['contact', 'parameter', 'epidemic', 'network', 'disease', 'transmission', 'rate', 'population', 'individual', 'model']\n",
      "\n",
      "\n",
      "Top 10 words for topic #34:\n",
      "['infected', 'zika', 'viral', 'flavivirus', 'chikv', 'mosquito', 'virus', 'dengue', 'denv', 'zikv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #35:\n",
      "['global', 'response', 'information', 'surveillance', 'outbreak', 'research', 'country', 'public', 'disease', 'health']\n",
      "\n",
      "\n",
      "Top 10 words for topic #36:\n",
      "['week', 'period', 'temperature', 'factor', 'risk', 'incidence', 'year', 'disease', 'case', 'cat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #37:\n",
      "['inhibitor', 'active', 'site', 'residue', 'catalytic', 'rdrp', 'protease', 'enzyme', 'substrate', 'activity']\n",
      "\n",
      "\n",
      "Top 10 words for topic #38:\n",
      "['covid', 'period', '19', 'china', 'day', 'medrxiv', 'transmission', 'epidemic', 'outbreak', 'case']\n",
      "\n",
      "\n",
      "Top 10 words for topic #39:\n",
      "['identity', 'specie', 'detected', 'region', 'positive', 'virus', 'genotype', 'strain', 'sample', 'sequence']\n",
      "\n",
      "\n",
      "Top 10 words for topic #40:\n",
      "['containing', 'fraction', 'cell', 'antibody', 'buffer', 'plant', 'expression', 'recombinant', 'purified', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #41:\n",
      "['antigen', 'group', 'virus', 'response', 'specific', 'anti', 'serum', 'cell', 'mouse', 'antibody']\n",
      "\n",
      "\n",
      "Top 10 words for topic #42:\n",
      "['receptor', 'membrane', 'residue', 'cell', 'protein', 'fusion', 'epitope', 'binding', 'hiv', 'peptide']\n",
      "\n",
      "\n",
      "Top 10 words for topic #43:\n",
      "['ang', 'adam17', 'small', 'apelin', 'target', 'domain', 'activity', 'sp', 'protein', 'ace2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #44:\n",
      "['cell', 'observed', 'disease', 'model', 'group', 'infected', 'tissue', 'animal', 'mouse', 'lung']\n",
      "\n",
      "\n",
      "Top 10 words for topic #45:\n",
      "['activity', 'complex', 'interaction', 'acid', 'protein', 'site', 'compound', 'residue', 'binding', 'structure']\n",
      "\n",
      "\n",
      "Top 10 words for topic #46:\n",
      "['region', 'host', 'human', 'specie', 'sequencing', 'read', 'viral', 'genome', 'sequence', 'virus']\n",
      "\n",
      "\n",
      "Top 10 words for topic #47:\n",
      "['algorithm', 'distribution', 'approach', 'distance', 'sequence', 'information', 'cluster', 'value', 'model', 'method']\n",
      "\n",
      "\n",
      "Top 10 words for topic #48:\n",
      "['assay', 'medium', 'concentration', 'titer', 'replication', 'ml', 'culture', 'viral', 'cell', 'virus']\n",
      "\n",
      "\n",
      "Top 10 words for topic #49:\n",
      "['infected', 'duck', 'mouse', 'strain', 'poultry', 'avian', 'bird', 'h5n1', 'chicken', 'virus']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values_countvectorizer = LDA.transform(doc_term_matrix_countvectorizer)\n",
    "topic_values_countvectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix_Tfidf = tfidf_vect.fit_transform(df_covid_for_nlp_10K['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x110226 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7517951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=50, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_Tfidf = LatentDirichletAllocation(n_components=50, random_state=42, n_jobs=-1)\n",
    "LDA_Tfidf.fit(doc_term_matrix_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discontinuity\n",
      "gucov\n",
      "masstag\n",
      "castillo\n",
      "naturalproduct\n",
      "1034\n",
      "sublineage\n",
      "barratt\n",
      "hlas\n",
      "cynomops\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA_Tfidf.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 76746,  44963,  46644,  24298, 100642,  74849,  59485,  85971,\n",
       "        43563,  82657], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per1\n",
      "gnp\n",
      "hace1\n",
      "chikf\n",
      "tocs\n",
      "pakit03\n",
      "letx\n",
      "reinitiation\n",
      "gemcitabine\n",
      "psgs\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "#     print(first_topic[i])\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['per1', 'gnp', 'hace1', 'chikf', 'tocs', 'pakit03', 'letx', 'reinitiation', 'gemcitabine', 'psgs']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['dcpep', 'coe', 'odns', 'gadd45b', 'l393', 'drill', 'ppg', 'egcg', 'egr', 'emodin']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['whcv', 'sod1', 'cpps', 'dnsp16', 'restv', 'igf', 'iecs', 'cccdna', 'sudv', 'spherule']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['ifi204', 'outsourcing', 'mdi', 'anguilla', 'rhmpv', 'rbp', 'serinc5', 'adam17', 'gx', 'pact']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['vhhs', 'avan', 'samhd1', 'ridd', 'hsp27', 'ccovs', 'eplex', 'binase', 'ire1α', 'grp78']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['il', 'cov', 'response', 'expression', 'antibody', 'viral', 'mouse', 'protein', 'virus', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['eif2α', 'hepg2', 'demyelination', 'cathepsin', 'astrovirus', 'orf2', 'astrocyte', 'golgi', 'microglia', 'chikv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['pinene', 'sporotrichosis', 'cdc42', 'fty720', 'pev', 'sab', 'g1670a', 'z2', 'a129', 'diii']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['lc3b', 'atg7', 'beclin', 'sdpp', 'autophagosomes', 'autophagosome', 'atg5', 'autophagic', 'lc3', 'autophagy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['hnscc', 'bohv', 'arg1', 'rosea', 'eef1bc', 'sv', '6b', 'hrqol', 'bicp0', 'ifnlr1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #10:\n",
      "['brdc', 'eri3', 'mdef201', 'chlamydial', 'cr3022', 'bhv', 'selex', 'felv', 'aptamer', 'aptamers']\n",
      "\n",
      "\n",
      "Top 10 words for topic #11:\n",
      "['lsdv', 'api5', 'rip3', 'ns1b', 'liquorice', 'phlorotannins', 'defs', 'wurss', 'ghsa', 'crt']\n",
      "\n",
      "\n",
      "Top 10 words for topic #12:\n",
      "['mβcd', 'faeg', 'trim56', 'acherv', 'arf1', 'auris', 'sonfh', 'iipcr', 'gbf1', 'g6pd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #13:\n",
      "['hypokalemia', 'timp', 'pgsa', 'myricitrin', 'crameri', 'holm', 'handrail', 'bzip60', 'bagv', 'ntcp']\n",
      "\n",
      "\n",
      "Top 10 words for topic #14:\n",
      "['mage', '1bb', 'dppiv', 'b19v', 'wechat', 'detections', 'thyroiditis', 'hbz', 'wssv', 'bmem']\n",
      "\n",
      "\n",
      "Top 10 words for topic #15:\n",
      "['pdk1', 'tcdd', 'map3k7', 'pfcrt', 'parp2', 'ilov', 'bacteriologically', 'candid', 'pessimism', 'optimism']\n",
      "\n",
      "\n",
      "Top 10 words for topic #16:\n",
      "['pga', 'fenofibrate', 'flotillin', 'gnp', 'cmah', 'biochar', 'chk2', 'schu', 'm102', 'bghv8']\n",
      "\n",
      "\n",
      "Top 10 words for topic #17:\n",
      "['ceacams', 'bleomycin', 'mbifitm3', 'cb4856', 'ipedvpt', 'pedvpt', 'rmp12', 'picv', 'p96', 'ctsl']\n",
      "\n",
      "\n",
      "Top 10 words for topic #18:\n",
      "['cbf1', 'm2e', 'sirt1', 'cvcva5', 'ra59', 'chws', 'dusp1', 'tfr1', 'sgta', 'cypa']\n",
      "\n",
      "\n",
      "Top 10 words for topic #19:\n",
      "['dhbv', 'ampv', 'csra', 'impdh', 'goitrin', 'hpev3', 'var2csa', '31ca', 'hpev1', 'hpev']\n",
      "\n",
      "\n",
      "Top 10 words for topic #20:\n",
      "['dystrophin', 'hcov', 'msc', 'femoral', 'hcovs', 'unigenes', 'piv', 'cftr', 'otus', 'ivig']\n",
      "\n",
      "\n",
      "Top 10 words for topic #21:\n",
      "['p17', 'becn1', 'dispensary', 'ifnl', 'skp2', 'nsip', 'vip', 'dpp', 'cd147', 'fgl2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #22:\n",
      "['read', 'primer', 'sample', 'strain', 'pedv', 'virus', 'genome', 'protein', 'gene', 'sequence']\n",
      "\n",
      "\n",
      "Top 10 words for topic #23:\n",
      "['command', 'outbreaker2', 'appendicitis', 'card9', 'hr1p', 'tibetan', 'megabat', 'hepaciviruses', 'r06e', 'microbat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #24:\n",
      "['comfa', 'trinidad', 'hdac5', 'tcrv', 'silymarin', 'onfh', 'fpr1', 'baseplate', 'rn', 'fpr2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #25:\n",
      "['epidemic', 'disease', 'medrxiv', 'model', 'hospital', 'child', 'respiratory', 'influenza', 'case', 'patient']\n",
      "\n",
      "\n",
      "Top 10 words for topic #26:\n",
      "['takizawa', 'cd200r1', 'eckol', 'viruliferous', 'slc26a4', 'breastfeeding', 'bnov', 'feedlot', 'brbv', 'spla']\n",
      "\n",
      "\n",
      "Top 10 words for topic #27:\n",
      "['sac1', 'atii', 'hsp40', 'mayv', 'ddx5', 'apelin', 'isdb', 'pyeongtaek', 'mt145k', 'hrid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #28:\n",
      "['dvgs', 'indirubin', 'charadriiformes', 'quercetin', 'rhifitm3', 'rpfs', 'limd1', 'g64s', 'isg20', 'fcrn']\n",
      "\n",
      "\n",
      "Top 10 words for topic #29:\n",
      "['mshmp', 'artis', 'phytol', 'sgiv', 'hais', 'richards', 'facemask', 'ndm', 'alri', 'hbov1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #30:\n",
      "['cakovs', 'ridership', 'foxo3a', '4glcnacb1', 'pmmv', 'vpu', 'rebov', 'ski', 'pcv3a', 'pcv3']\n",
      "\n",
      "\n",
      "Top 10 words for topic #31:\n",
      "['qlamp', 'tiger', '1h', 'aoaa', 'gldc', 'leopard', 'rzikv', 'ndiv', 'vidisca', 'ly6e']\n",
      "\n",
      "\n",
      "Top 10 words for topic #32:\n",
      "['cordyceps', 'smad', 'ibalt', 'haze', 'cadv', 'hvppi', 'fbov', 'cress', 'mbd', 'apmv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #33:\n",
      "['bat', 'outbreak', 'animal', 'country', 'human', 'public', 'specie', 'virus', 'disease', 'health']\n",
      "\n",
      "\n",
      "Top 10 words for topic #34:\n",
      "['abaecin', 'sd16', 'idus', 'muc4', 'kdelr2', 'h10n8', 'asiaflucap', 'valinomycin', 'mupyv', 'seov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #35:\n",
      "['hastv1', 'astv', 'cycloaddition', 'manidipine', 'cirmf', 'pparγ', 'ube1l', 'guest', 'ab10', 'cerebellitis']\n",
      "\n",
      "\n",
      "Top 10 words for topic #36:\n",
      "['diphyllin', 'pafb', 'blame', 'dbs', 'prds', 'vp6', 'penguin', 'defensins', 'hnp1', 'usp15']\n",
      "\n",
      "\n",
      "Top 10 words for topic #37:\n",
      "['tc83', 'jx', 'oocyst', 'crime', 'ntcp', 'sadc', 'mpxv', 'apelin', 'rosavirus', 'tcdc']\n",
      "\n",
      "\n",
      "Top 10 words for topic #38:\n",
      "['alaska', 'gsk3', 'ascs', '2216', 'mrv3', 'errps', 'rha', 'htim1', 'anxa2', 'tbtv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #39:\n",
      "['sace2', 'diub', 'sag1', 'sla', 'rlcmv', 'ahsg', 'tachyzoites', 'usp28', 'td', 'emr2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #40:\n",
      "['hcp', 'frcs', 'gabhs', 'hevs', 'pscnv', 'quercetin', 'am580', 'tmadv', 'deps', 'itraq']\n",
      "\n",
      "\n",
      "Top 10 words for topic #41:\n",
      "['toxocariasis', 'urate', 'usp2', 'jak3', 'adhu5', 'mesothelin', 'adam10', 'tylcv', 'nhbe', 'mav']\n",
      "\n",
      "\n",
      "Top 10 words for topic #42:\n",
      "['sss', 'irs', 'rscv', 'cd200', 'cd200r', 'isav', 'asean', 'ecov', 'pams', 'eef1a']\n",
      "\n",
      "\n",
      "Top 10 words for topic #43:\n",
      "['bv', 'zhuhai', '5734', 'myricetin', 'usage', 'gc3s', 'bmnpv', 'acmnpv', 'rscu', 'nsp11']\n",
      "\n",
      "\n",
      "Top 10 words for topic #44:\n",
      "['galloyl', 'montelukast', 'ccfr', 'panad3', 'rmva', 'dogcv', 'neopterin', 'adenoid', 'b1648', 'rtd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #45:\n",
      "['cgcov', 'verdinexor', 'lc16m8', 'lfd', 'adap2', 'par1', 'supertype', 'xenotransplantation', 'npis', 'xrn1p']\n",
      "\n",
      "\n",
      "Top 10 words for topic #46:\n",
      "['ddpcr', 'afp', '1a', 'zippered', 'virochip', 'mpcr', 'pbvs', 'hev71', 'psav', 'lecb']\n",
      "\n",
      "\n",
      "Top 10 words for topic #47:\n",
      "['cpi', 'rigida', 'dasatinib', 'p90rsk', 'siba', 'pomegranate', 'pbd', 'casd1', 'nc8', 'ltcfs']\n",
      "\n",
      "\n",
      "Top 10 words for topic #48:\n",
      "['iift', 'dorf3', 'pcp', 'rbd219', 'catl', 'bamv', 'catb', 'apod', 'bactrian', 'ceacam1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #49:\n",
      "['endoscope', 'pafb', 'dhav', 'cnic', 'trem', 'mkp', 'renalase', 'fima', 'usp14', 'ncip']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA_Tfidf.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values_tfidf = LDA_Tfidf.transform(doc_term_matrix_Tfidf)\n",
    "topic_values_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(topic_values_tfidf))\n",
    "df_topic_values_tfidf = pd.DataFrame(topic_values_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.378510</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.044324</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.160525</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.348331</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.038035</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.001562  0.001562  0.001562  0.001562  0.001562  0.378510  0.009503   \n",
       "1  0.002012  0.002012  0.002012  0.044324  0.002012  0.010554  0.002012   \n",
       "2  0.001524  0.001524  0.022740  0.001524  0.001524  0.160525  0.035983   \n",
       "3  0.001314  0.001314  0.001314  0.001314  0.001314  0.348331  0.018190   \n",
       "4  0.001592  0.001592  0.001592  0.001592  0.001592  0.038035  0.007470   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0  0.001562  0.001562  0.001562  ...  0.001562  0.001562  0.001562  0.001562   \n",
       "1  0.002012  0.002012  0.002012  ...  0.002012  0.002012  0.002012  0.002012   \n",
       "2  0.001524  0.001524  0.001524  ...  0.001524  0.001524  0.001524  0.001524   \n",
       "3  0.001314  0.001314  0.001314  ...  0.001314  0.001314  0.001314  0.018697   \n",
       "4  0.013788  0.001592  0.001592  ...  0.001592  0.001592  0.001592  0.001592   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0  0.001562  0.001562  0.001562  0.001562  0.001562  0.001562  \n",
       "1  0.002012  0.002012  0.002012  0.002012  0.002012  0.002012  \n",
       "2  0.001524  0.001524  0.001524  0.001524  0.001524  0.001524  \n",
       "3  0.005784  0.001314  0.001314  0.001314  0.001314  0.001314  \n",
       "4  0.001592  0.001592  0.001592  0.001592  0.001592  0.001592  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_values_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0 from CountVectoizer:\n",
      "['viral', 'structure', 'pcv2', 'replication', 'vesicle', 'infected', 'virus', 'cell', 'membrane', 'prrsv']\n",
      "Top 10 words for topic #0 from Tfidf:\n",
      "['per1', 'gnp', 'hace1', 'chikf', 'tocs', 'pakit03', 'letx', 'reinitiation', 'gemcitabine', 'psgs']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1 from CountVectoizer:\n",
      "['stem', 'ribosome', 'frame', 'trna', 'frameshifting', 'sequence', 'translation', 'site', 'mrna', 'codon']\n",
      "Top 10 words for topic #1 from Tfidf:\n",
      "['dcpep', 'coe', 'odns', 'gadd45b', 'l393', 'drill', 'ppg', 'egcg', 'egr', 'emodin']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2 from CountVectoizer:\n",
      "['cell', 'genome', 'interaction', 'ifitm3', 'host', 'replication', 'domain', 'viral', 'virus', 'protein']\n",
      "Top 10 words for topic #2 from Tfidf:\n",
      "['whcv', 'sod1', 'cpps', 'dnsp16', 'restv', 'igf', 'iecs', 'cccdna', 'sudv', 'spherule']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3 from CountVectoizer:\n",
      "['method', 'positive', 'probe', 'reaction', 'pcr', 'rt', 'detection', 'primer', 'assay', 'sample']\n",
      "Top 10 words for topic #3 from Tfidf:\n",
      "['ifi204', 'outsourcing', 'mdi', 'anguilla', 'rhmpv', 'rbp', 'serinc5', 'adam17', 'gx', 'pact']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4 from CountVectoizer:\n",
      "['host', 'immune', 'activation', 'ifn', 'type', 'protein', 'response', 'viral', 'virus', 'cell']\n",
      "Top 10 words for topic #4 from Tfidf:\n",
      "['vhhs', 'avan', 'samhd1', 'ridd', 'hsp27', 'ccovs', 'eplex', 'binase', 'ire1α', 'grp78']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5 from CountVectoizer:\n",
      "['protein', 'vector', 'human', 'immune', 'virus', 'antigen', 'antibody', 'response', 'cell', 'vaccine']\n",
      "Top 10 words for topic #5 from Tfidf:\n",
      "['il', 'cov', 'response', 'expression', 'antibody', 'viral', 'mouse', 'protein', 'virus', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6 from CountVectoizer:\n",
      "['anti', 'immune', 'level', 'macrophage', 'response', 'cytokine', 'expression', 'mouse', 'il', 'cell']\n",
      "Top 10 words for topic #6 from Tfidf:\n",
      "['eif2α', 'hepg2', 'demyelination', 'cathepsin', 'astrovirus', 'orf2', 'astrocyte', 'golgi', 'microglia', 'chikv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7 from CountVectoizer:\n",
      "['coronaviruses', 'hcov', 'coronavirus', 'camel', 'bat', 'virus', 'human', 'sars', 'mers', 'cov']\n",
      "Top 10 words for topic #7 from Tfidf:\n",
      "['pinene', 'sporotrichosis', 'cdc42', 'fty720', 'pev', 'sab', 'g1670a', 'z2', 'a129', 'diii']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8 from CountVectoizer:\n",
      "['protein', 'acid', 'amino', 'genome', 'codon', 'isolates', 'mutation', 'sequence', 'gene', 'strain']\n",
      "Top 10 words for topic #8 from Tfidf:\n",
      "['lc3b', 'atg7', 'beclin', 'sdpp', 'autophagosomes', 'autophagosome', 'atg5', 'autophagic', 'lc3', 'autophagy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9 from CountVectoizer:\n",
      "['ebov', 'effect', 'inhibitor', 'viral', 'treated', 'protein', 'virus', 'entry', 'infected', 'cell']\n",
      "Top 10 words for topic #9 from Tfidf:\n",
      "['hnscc', 'bohv', 'arg1', 'rosea', 'eef1bc', 'sv', '6b', 'hrqol', 'bicp0', 'ifnlr1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #10 from CountVectoizer:\n",
      "['sample', 'case', 'clinical', 'pneumonia', 'pathogen', 'viral', 'patient', 'virus', 'child', 'respiratory']\n",
      "Top 10 words for topic #10 from Tfidf:\n",
      "['brdc', 'eri3', 'mdef201', 'chlamydial', 'cr3022', 'bhv', 'selex', 'felv', 'aptamer', 'aptamers']\n",
      "\n",
      "\n",
      "Top 10 words for topic #11 from CountVectoizer:\n",
      "['sequencing', 'hadv', 'community', 'microbiota', 'microbial', 'specie', 'pathogen', 'bacteria', 'bacterial', 'sample']\n",
      "Top 10 words for topic #11 from Tfidf:\n",
      "['lsdv', 'api5', 'rip3', 'ns1b', 'liquorice', 'phlorotannins', 'defs', 'wurss', 'ghsa', 'crt']\n",
      "\n",
      "\n",
      "Top 10 words for topic #12 from CountVectoizer:\n",
      "['replication', 'control', 'viral', 'culture', 'level', 'gene', 'virus', 'infected', 'expression', 'cell']\n",
      "Top 10 words for topic #12 from Tfidf:\n",
      "['mβcd', 'faeg', 'trim56', 'acherv', 'arf1', 'auris', 'sonfh', 'iipcr', 'gbf1', 'g6pd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #13 from CountVectoizer:\n",
      "['mouse', 'cell', 'ifn', 'gondii', 'gene', 'stat1', 'expression', 'infected', 'cov', 'sars']\n",
      "Top 10 words for topic #13 from Tfidf:\n",
      "['hypokalemia', 'timp', 'pgsa', 'myricitrin', 'crameri', 'holm', 'handrail', 'bzip60', 'bagv', 'ntcp']\n",
      "\n",
      "\n",
      "Top 10 words for topic #14 from CountVectoizer:\n",
      "['day', 'allergic', 'clinical', 'symptom', 'effect', 'subject', 'trial', 'group', 'asthma', 'treatment']\n",
      "Top 10 words for topic #14 from Tfidf:\n",
      "['mage', '1bb', 'dppiv', 'b19v', 'wechat', 'detections', 'thyroiditis', 'hbz', 'wssv', 'bmem']\n",
      "\n",
      "\n",
      "Top 10 words for topic #15 from CountVectoizer:\n",
      "['control', 'intestinal', 'astrocyte', 'calf', 'microglia', 'animal', 'neuron', 'group', 'mouse', 'brain']\n",
      "Top 10 words for topic #15 from Tfidf:\n",
      "['pdk1', 'tcdd', 'map3k7', 'pfcrt', 'parp2', 'ilov', 'bacteriologically', 'candid', 'pessimism', 'optimism']\n",
      "\n",
      "\n",
      "Top 10 words for topic #16 from CountVectoizer:\n",
      "['2013', '2011', 'treatment', 'target', '2012', 'antiviral', 'compound', 'activity', 'effect', 'drug']\n",
      "Top 10 words for topic #16 from Tfidf:\n",
      "['pga', 'fenofibrate', 'flotillin', 'gnp', 'cmah', 'biochar', 'chk2', 'schu', 'm102', 'bghv8']\n",
      "\n",
      "\n",
      "Top 10 words for topic #17 from CountVectoizer:\n",
      "['virus', 'aptamers', 'pdcov', 'farm', 'porcine', 'swine', 'tgev', 'piglet', 'pig', 'pedv']\n",
      "Top 10 words for topic #17 from Tfidf:\n",
      "['ceacams', 'bleomycin', 'mbifitm3', 'cb4856', 'ipedvpt', 'pedvpt', 'rmp12', 'picv', 'p96', 'ctsl']\n",
      "\n",
      "\n",
      "Top 10 words for topic #18 from CountVectoizer:\n",
      "['compared', 'immune', 'control', 'challenge', 'level', 'response', 'vaccinated', 'vaccine', 'vaccination', 'group']\n",
      "Top 10 words for topic #18 from Tfidf:\n",
      "['cbf1', 'm2e', 'sirt1', 'cvcva5', 'ra59', 'chws', 'dusp1', 'tfr1', 'sgta', 'cypa']\n",
      "\n",
      "\n",
      "Top 10 words for topic #19 from CountVectoizer:\n",
      "['cc', '1101', 'doi', 'funder', 'org', '10', 'reviewed', 'author', 'peer', 'holder']\n",
      "Top 10 words for topic #19 from Tfidf:\n",
      "['dhbv', 'ampv', 'csra', 'impdh', 'goitrin', 'hpev3', 'var2csa', '31ca', 'hpev1', 'hpev']\n",
      "\n",
      "\n",
      "Top 10 words for topic #20 from CountVectoizer:\n",
      "['formation', 'pathway', 'viral', 'replication', 'lipid', 'membrane', 'stress', 'cell', 'protein', 'autophagy']\n",
      "Top 10 words for topic #20 from Tfidf:\n",
      "['dystrophin', 'hcov', 'msc', 'femoral', 'hcovs', 'unigenes', 'piv', 'cftr', 'otus', 'ivig']\n",
      "\n",
      "\n",
      "Top 10 words for topic #21 from CountVectoizer:\n",
      "['rna', 'ifit1', 'stable', 'yeast', 'cell', 'mrna', 'expression', 'strain', 'reference', 'gene']\n",
      "Top 10 words for topic #21 from Tfidf:\n",
      "['p17', 'becn1', 'dispensary', 'ifnl', 'skp2', 'nsip', 'vip', 'dpp', 'cd147', 'fgl2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #22 from CountVectoizer:\n",
      "['expression', 'network', 'lncrnas', 'function', 'peptide', 'mass', 'sample', 'identified', 'ms', 'protein']\n",
      "Top 10 words for topic #22 from Tfidf:\n",
      "['read', 'primer', 'sample', 'strain', 'pedv', 'virus', 'genome', 'protein', 'gene', 'sequence']\n",
      "\n",
      "\n",
      "Top 10 words for topic #23 from CountVectoizer:\n",
      "['farm', 'wild', 'transmission', 'population', 'disease', 'pathogen', 'human', 'host', 'specie', 'animal']\n",
      "Top 10 words for topic #23 from Tfidf:\n",
      "['command', 'outbreaker2', 'appendicitis', 'card9', 'hr1p', 'tibetan', 'megabat', 'hepaciviruses', 'r06e', 'microbat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #24 from CountVectoizer:\n",
      "['level', 'associated', 'identified', 'expressed', 'pathway', 'response', 'transcript', 'table', 'expression', 'gene']\n",
      "Top 10 words for topic #24 from Tfidf:\n",
      "['comfa', 'trinidad', 'hdac5', 'tcrv', 'silymarin', 'onfh', 'fpr1', 'baseplate', 'rn', 'fpr2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #25 from CountVectoizer:\n",
      "['mortality', 'associated', 'level', 'blood', 'treatment', 'group', 'clinical', 'severe', 'disease', 'patient']\n",
      "Top 10 words for topic #25 from Tfidf:\n",
      "['epidemic', 'disease', 'medrxiv', 'model', 'hospital', 'child', 'respiratory', 'influenza', 'case', 'patient']\n",
      "\n",
      "\n",
      "Top 10 words for topic #26 from CountVectoizer:\n",
      "['ncov', '2019', 'level', '5p', 'target', 'expression', 'cell', 'mirna', 'mirnas', 'mir']\n",
      "Top 10 words for topic #26 from Tfidf:\n",
      "['takizawa', 'cd200r1', 'eckol', 'viruliferous', 'slc26a4', 'breastfeeding', 'bnov', 'feedlot', 'brbv', 'spla']\n",
      "\n",
      "\n",
      "Top 10 words for topic #27 from CountVectoizer:\n",
      "['group', 'reported', 'year', 'medical', 'risk', 'health', 'participant', 'care', 'patient', 'hospital']\n",
      "Top 10 words for topic #27 from Tfidf:\n",
      "['sac1', 'atii', 'hsp40', 'mayv', 'ddx5', 'apelin', 'isdb', 'pyeongtaek', 'mt145k', 'hrid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #28 from CountVectoizer:\n",
      "['treatment', 'level', 'anti', 'induced', 'expression', 'effect', 'tumor', 'activity', 'cancer', 'cell']\n",
      "Top 10 words for topic #28 from Tfidf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dvgs', 'indirubin', 'charadriiformes', 'quercetin', 'rhifitm3', 'rpfs', 'limd1', 'g64s', 'isg20', 'fcrn']\n",
      "\n",
      "\n",
      "Top 10 words for topic #29 from CountVectoizer:\n",
      "['solution', 'detection', 'phage', 'image', 'sample', 'method', 'temperature', 'concentration', 'surface', 'particle']\n",
      "Top 10 words for topic #29 from Tfidf:\n",
      "['mshmp', 'artis', 'phytol', 'sgiv', 'hais', 'richards', 'facemask', 'ndm', 'alri', 'hbov1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #30 from CountVectoizer:\n",
      "['virus', 'domain', 'transfected', 'viral', 'expression', 'plasmid', 'binding', 'mutant', 'cell', 'protein']\n",
      "Top 10 words for topic #30 from Tfidf:\n",
      "['cakovs', 'ridership', 'foxo3a', '4glcnacb1', 'pmmv', 'vpu', 'rebov', 'ski', 'pcv3a', 'pcv3']\n",
      "\n",
      "\n",
      "Top 10 words for topic #31 from CountVectoizer:\n",
      "['genetic', 'population', 'sequence', 'position', 'allele', 'rabv', 'strain', 'rabies', 'rvfv', 'variant']\n",
      "Top 10 words for topic #31 from Tfidf:\n",
      "['qlamp', 'tiger', '1h', 'aoaa', 'gldc', 'leopard', 'rzikv', 'ndiv', 'vidisca', 'ly6e']\n",
      "\n",
      "\n",
      "Top 10 words for topic #32 from CountVectoizer:\n",
      "['patient', 'year', 'surveillance', '2009', 'respiratory', 'case', 'pandemic', 'h1n1', 'virus', 'influenza']\n",
      "Top 10 words for topic #32 from Tfidf:\n",
      "['cordyceps', 'smad', 'ibalt', 'haze', 'cadv', 'hvppi', 'fbov', 'cress', 'mbd', 'apmv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #33 from CountVectoizer:\n",
      "['contact', 'parameter', 'epidemic', 'network', 'disease', 'transmission', 'rate', 'population', 'individual', 'model']\n",
      "Top 10 words for topic #33 from Tfidf:\n",
      "['bat', 'outbreak', 'animal', 'country', 'human', 'public', 'specie', 'virus', 'disease', 'health']\n",
      "\n",
      "\n",
      "Top 10 words for topic #34 from CountVectoizer:\n",
      "['infected', 'zika', 'viral', 'flavivirus', 'chikv', 'mosquito', 'virus', 'dengue', 'denv', 'zikv']\n",
      "Top 10 words for topic #34 from Tfidf:\n",
      "['abaecin', 'sd16', 'idus', 'muc4', 'kdelr2', 'h10n8', 'asiaflucap', 'valinomycin', 'mupyv', 'seov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #35 from CountVectoizer:\n",
      "['global', 'response', 'information', 'surveillance', 'outbreak', 'research', 'country', 'public', 'disease', 'health']\n",
      "Top 10 words for topic #35 from Tfidf:\n",
      "['hastv1', 'astv', 'cycloaddition', 'manidipine', 'cirmf', 'pparγ', 'ube1l', 'guest', 'ab10', 'cerebellitis']\n",
      "\n",
      "\n",
      "Top 10 words for topic #36 from CountVectoizer:\n",
      "['week', 'period', 'temperature', 'factor', 'risk', 'incidence', 'year', 'disease', 'case', 'cat']\n",
      "Top 10 words for topic #36 from Tfidf:\n",
      "['diphyllin', 'pafb', 'blame', 'dbs', 'prds', 'vp6', 'penguin', 'defensins', 'hnp1', 'usp15']\n",
      "\n",
      "\n",
      "Top 10 words for topic #37 from CountVectoizer:\n",
      "['inhibitor', 'active', 'site', 'residue', 'catalytic', 'rdrp', 'protease', 'enzyme', 'substrate', 'activity']\n",
      "Top 10 words for topic #37 from Tfidf:\n",
      "['tc83', 'jx', 'oocyst', 'crime', 'ntcp', 'sadc', 'mpxv', 'apelin', 'rosavirus', 'tcdc']\n",
      "\n",
      "\n",
      "Top 10 words for topic #38 from CountVectoizer:\n",
      "['covid', 'period', '19', 'china', 'day', 'medrxiv', 'transmission', 'epidemic', 'outbreak', 'case']\n",
      "Top 10 words for topic #38 from Tfidf:\n",
      "['alaska', 'gsk3', 'ascs', '2216', 'mrv3', 'errps', 'rha', 'htim1', 'anxa2', 'tbtv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #39 from CountVectoizer:\n",
      "['identity', 'specie', 'detected', 'region', 'positive', 'virus', 'genotype', 'strain', 'sample', 'sequence']\n",
      "Top 10 words for topic #39 from Tfidf:\n",
      "['sace2', 'diub', 'sag1', 'sla', 'rlcmv', 'ahsg', 'tachyzoites', 'usp28', 'td', 'emr2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #40 from CountVectoizer:\n",
      "['containing', 'fraction', 'cell', 'antibody', 'buffer', 'plant', 'expression', 'recombinant', 'purified', 'protein']\n",
      "Top 10 words for topic #40 from Tfidf:\n",
      "['hcp', 'frcs', 'gabhs', 'hevs', 'pscnv', 'quercetin', 'am580', 'tmadv', 'deps', 'itraq']\n",
      "\n",
      "\n",
      "Top 10 words for topic #41 from CountVectoizer:\n",
      "['antigen', 'group', 'virus', 'response', 'specific', 'anti', 'serum', 'cell', 'mouse', 'antibody']\n",
      "Top 10 words for topic #41 from Tfidf:\n",
      "['toxocariasis', 'urate', 'usp2', 'jak3', 'adhu5', 'mesothelin', 'adam10', 'tylcv', 'nhbe', 'mav']\n",
      "\n",
      "\n",
      "Top 10 words for topic #42 from CountVectoizer:\n",
      "['receptor', 'membrane', 'residue', 'cell', 'protein', 'fusion', 'epitope', 'binding', 'hiv', 'peptide']\n",
      "Top 10 words for topic #42 from Tfidf:\n",
      "['sss', 'irs', 'rscv', 'cd200', 'cd200r', 'isav', 'asean', 'ecov', 'pams', 'eef1a']\n",
      "\n",
      "\n",
      "Top 10 words for topic #43 from CountVectoizer:\n",
      "['ang', 'adam17', 'small', 'apelin', 'target', 'domain', 'activity', 'sp', 'protein', 'ace2']\n",
      "Top 10 words for topic #43 from Tfidf:\n",
      "['bv', 'zhuhai', '5734', 'myricetin', 'usage', 'gc3s', 'bmnpv', 'acmnpv', 'rscu', 'nsp11']\n",
      "\n",
      "\n",
      "Top 10 words for topic #44 from CountVectoizer:\n",
      "['cell', 'observed', 'disease', 'model', 'group', 'infected', 'tissue', 'animal', 'mouse', 'lung']\n",
      "Top 10 words for topic #44 from Tfidf:\n",
      "['galloyl', 'montelukast', 'ccfr', 'panad3', 'rmva', 'dogcv', 'neopterin', 'adenoid', 'b1648', 'rtd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #45 from CountVectoizer:\n",
      "['activity', 'complex', 'interaction', 'acid', 'protein', 'site', 'compound', 'residue', 'binding', 'structure']\n",
      "Top 10 words for topic #45 from Tfidf:\n",
      "['cgcov', 'verdinexor', 'lc16m8', 'lfd', 'adap2', 'par1', 'supertype', 'xenotransplantation', 'npis', 'xrn1p']\n",
      "\n",
      "\n",
      "Top 10 words for topic #46 from CountVectoizer:\n",
      "['region', 'host', 'human', 'specie', 'sequencing', 'read', 'viral', 'genome', 'sequence', 'virus']\n",
      "Top 10 words for topic #46 from Tfidf:\n",
      "['ddpcr', 'afp', '1a', 'zippered', 'virochip', 'mpcr', 'pbvs', 'hev71', 'psav', 'lecb']\n",
      "\n",
      "\n",
      "Top 10 words for topic #47 from CountVectoizer:\n",
      "['algorithm', 'distribution', 'approach', 'distance', 'sequence', 'information', 'cluster', 'value', 'model', 'method']\n",
      "Top 10 words for topic #47 from Tfidf:\n",
      "['cpi', 'rigida', 'dasatinib', 'p90rsk', 'siba', 'pomegranate', 'pbd', 'casd1', 'nc8', 'ltcfs']\n",
      "\n",
      "\n",
      "Top 10 words for topic #48 from CountVectoizer:\n",
      "['assay', 'medium', 'concentration', 'titer', 'replication', 'ml', 'culture', 'viral', 'cell', 'virus']\n",
      "Top 10 words for topic #48 from Tfidf:\n",
      "['iift', 'dorf3', 'pcp', 'rbd219', 'catl', 'bamv', 'catb', 'apod', 'bactrian', 'ceacam1']\n",
      "\n",
      "\n",
      "Top 10 words for topic #49 from CountVectoizer:\n",
      "['infected', 'duck', 'mouse', 'strain', 'poultry', 'avian', 'bird', 'h5n1', 'chicken', 'virus']\n",
      "Top 10 words for topic #49 from Tfidf:\n",
      "['endoscope', 'pafb', 'dhav', 'cnic', 'trem', 'mkp', 'renalase', 'fima', 'usp14', 'ncip']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (topic_count_vect, topic_tfidf) in enumerate(zip(LDA.components_, LDA_Tfidf.components_)):\n",
    "    print(f'Top 10 words for topic #{i} from CountVectoizer:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic_count_vect.argsort()[-10:]])\n",
    "    print(f'Top 10 words for topic #{i} from Tfidf:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic_tfidf.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_for_nlp_10K['topic_count_vector'] = topic_values_countvectorizer.argmax(axis=1)\n",
    "df_covid_for_nlp_10K['topic_tfidf'] = topic_values_tfidf.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>topic_count_vector</th>\n",
       "      <th>topic_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 text word count: 5168 23 24...</td>\n",
       "      <td>vp3, and vp0 (which is further processed to vp...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "      <td>processed virus assembly region encode non-str...</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>the 2019-ncov epidemic has spread across china...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>2019-ncov epidemic spread across china country...</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>infectious bronchitis (ib) causes significant ...</td>\n",
       "      <td>infectious bronchitis (ib), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "      <td>infectious bronchitis caused infectious bronch...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  infectious bronchitis (ib) causes significant ...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  vp3, and vp0 (which is further processed to vp...                  241   \n",
       "1  the 2019-ncov epidemic has spread across china...                    0   \n",
       "2  infectious bronchitis (ib), which is caused by...                 1647   \n",
       "\n",
       "   body_word_count                                       cleaned_text  \\\n",
       "0             1728  processed virus assembly region encode non-str...   \n",
       "1              755  2019-ncov epidemic spread across china country...   \n",
       "2             4003  infectious bronchitis caused infectious bronch...   \n",
       "\n",
       "   topic_count_vector  topic_tfidf  \n",
       "0                  30           22  \n",
       "1                  38           25  \n",
       "2                   3           22  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp_10K.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_number_count_vector</th>\n",
       "      <th>topic_words_count_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[viral, structure, pcv2, replication, vesicle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[stem, ribosome, frame, trna, frameshifting, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[cell, genome, interaction, ifitm3, host, repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[method, positive, probe, reaction, pcr, rt, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[host, immune, activation, ifn, type, protein,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_number_count_vector  \\\n",
       "0                          0   \n",
       "1                          1   \n",
       "2                          2   \n",
       "3                          3   \n",
       "4                          4   \n",
       "\n",
       "                            topic_words_count_vector  \n",
       "0  [viral, structure, pcv2, replication, vesicle,...  \n",
       "1  [stem, ribosome, frame, trna, frameshifting, s...  \n",
       "2  [cell, genome, interaction, ifitm3, host, repl...  \n",
       "3  [method, positive, probe, reaction, pcr, rt, d...  \n",
       "4  [host, immune, activation, ifn, type, protein,...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_topic = {'topic_number_count_vector': [], 'topic_words_count_vector': []}\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    dict_topic['topic_number_count_vector'].append(i)\n",
    "    dict_topic['topic_words_count_vector'].append([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "\n",
    "df_covid_topics_count_vector = pd.DataFrame(dict_topic, columns=['topic_number_count_vector', 'topic_words_count_vector'])\n",
    "df_covid_topics_count_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[per1, gnp, hace1, chikf, tocs, pakit03, letx,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[dcpep, coe, odns, gadd45b, l393, drill, ppg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[whcv, sod1, cpps, dnsp16, restv, igf, iecs, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[ifi204, outsourcing, mdi, anguilla, rhmpv, rb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[vhhs, avan, samhd1, ridd, hsp27, ccovs, eplex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_number                                        topic_words\n",
       "0             0  [per1, gnp, hace1, chikf, tocs, pakit03, letx,...\n",
       "1             1  [dcpep, coe, odns, gadd45b, l393, drill, ppg, ...\n",
       "2             2  [whcv, sod1, cpps, dnsp16, restv, igf, iecs, c...\n",
       "3             3  [ifi204, outsourcing, mdi, anguilla, rhmpv, rb...\n",
       "4             4  [vhhs, avan, samhd1, ridd, hsp27, ccovs, eplex..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_topic = {'topic_number_tfidf': [], 'topic_words_tfidf': []}\n",
    "\n",
    "for i,topic in enumerate(LDA_Tfidf.components_):\n",
    "    dict_topic['topic_number_tfidf'].append(i)\n",
    "    dict_topic['topic_words_tfidf'].append([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "\n",
    "df_covid_topics_tfidf = pd.DataFrame(dict_topic, columns=['topic_number_tfidf', 'topic_words_tfidf'])\n",
    "df_covid_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_for_nlp_10K = df_covid_for_nlp_10K.merge(df_covid_topics_count_vector, how='left', left_on='topic_count_vector', right_on='topic_number_count_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_for_nlp_10K = df_covid_for_nlp_10K.merge(df_covid_topics_tfidf, how='left', left_on='topic_tfidf', right_on='topic_number_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>topic_count_vector</th>\n",
       "      <th>topic_tfidf</th>\n",
       "      <th>topic_number_count_vector</th>\n",
       "      <th>topic_words_count_vector</th>\n",
       "      <th>topic_number_tfidf</th>\n",
       "      <th>topic_words_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 text word count: 5168 23 24...</td>\n",
       "      <td>vp3, and vp0 (which is further processed to vp...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "      <td>processed virus assembly region encode non-str...</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>[virus, domain, transfected, viral, expression...</td>\n",
       "      <td>22</td>\n",
       "      <td>[read, primer, sample, strain, pedv, virus, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>the 2019-ncov epidemic has spread across china...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>2019-ncov epidemic spread across china country...</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>[covid, period, 19, china, day, medrxiv, trans...</td>\n",
       "      <td>25</td>\n",
       "      <td>[epidemic, disease, medrxiv, model, hospital, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>infectious bronchitis (ib) causes significant ...</td>\n",
       "      <td>infectious bronchitis (ib), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "      <td>infectious bronchitis caused infectious bronch...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>[method, positive, probe, reaction, pcr, rt, d...</td>\n",
       "      <td>22</td>\n",
       "      <td>[read, primer, sample, strain, pedv, virus, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>nipah virus (niv) came into limelight recently...</td>\n",
       "      <td>nipah is an infectious negative-sense single-s...</td>\n",
       "      <td>326</td>\n",
       "      <td>2399</td>\n",
       "      <td>nipah infectious negative-sense single-strande...</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>[activity, complex, interaction, acid, protein...</td>\n",
       "      <td>5</td>\n",
       "      <td>[il, cov, response, expression, antibody, vira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>background: a novel coronavirus (2019-ncov) em...</td>\n",
       "      <td>in december 2019, a cluster of patients with p...</td>\n",
       "      <td>22</td>\n",
       "      <td>4642</td>\n",
       "      <td>december 2019 cluster patient pneumonia unknow...</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>[covid, period, 19, china, day, medrxiv, trans...</td>\n",
       "      <td>25</td>\n",
       "      <td>[epidemic, disease, medrxiv, model, hospital, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  infectious bronchitis (ib) causes significant ...   \n",
       "3  nipah virus (niv) came into limelight recently...   \n",
       "4  background: a novel coronavirus (2019-ncov) em...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  vp3, and vp0 (which is further processed to vp...                  241   \n",
       "1  the 2019-ncov epidemic has spread across china...                    0   \n",
       "2  infectious bronchitis (ib), which is caused by...                 1647   \n",
       "3  nipah is an infectious negative-sense single-s...                  326   \n",
       "4  in december 2019, a cluster of patients with p...                   22   \n",
       "\n",
       "   body_word_count                                       cleaned_text  \\\n",
       "0             1728  processed virus assembly region encode non-str...   \n",
       "1              755  2019-ncov epidemic spread across china country...   \n",
       "2             4003  infectious bronchitis caused infectious bronch...   \n",
       "3             2399  nipah infectious negative-sense single-strande...   \n",
       "4             4642  december 2019 cluster patient pneumonia unknow...   \n",
       "\n",
       "   topic_count_vector  topic_tfidf  topic_number_count_vector  \\\n",
       "0                  30           22                         30   \n",
       "1                  38           25                         38   \n",
       "2                   3           22                          3   \n",
       "3                  45            5                         45   \n",
       "4                  38           25                         38   \n",
       "\n",
       "                            topic_words_count_vector  topic_number_tfidf  \\\n",
       "0  [virus, domain, transfected, viral, expression...                  22   \n",
       "1  [covid, period, 19, china, day, medrxiv, trans...                  25   \n",
       "2  [method, positive, probe, reaction, pcr, rt, d...                  22   \n",
       "3  [activity, complex, interaction, acid, protein...                   5   \n",
       "4  [covid, period, 19, china, day, medrxiv, trans...                  25   \n",
       "\n",
       "                                   topic_words_tfidf  \n",
       "0  [read, primer, sample, strain, pedv, virus, ge...  \n",
       "1  [epidemic, disease, medrxiv, model, hospital, ...  \n",
       "2  [read, primer, sample, strain, pedv, virus, ge...  \n",
       "3  [il, cov, response, expression, antibody, vira...  \n",
       "4  [epidemic, disease, medrxiv, model, hospital, ...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp_10K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'abstract', 'body_text', 'abstract_word_count',\n",
       "       'body_word_count', 'cleaned_text', 'topic_count_vector', 'topic_tfidf',\n",
       "       'topic_number_count_vector', 'topic_words_count_vector',\n",
       "       'topic_number_tfidf', 'topic_words_tfidf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp_10K.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_covid_for_nlp_10K[['paper_id', 'body_text', 'body_word_count', 'topic_count_vector', 'topic_words_count_vector', 'topic_tfidf', 'topic_words_tfidf']].head()\n",
    "# df_covid_for_nlp_10K[['paper_id', 'body_text', 'body_word_count', 'topic_count_vector', 'topic_words_count_vector', 'topic_tfidf', 'topic_words_tfidf']].to_csv(output / 'df_covid_for_nlp_10K.csv', index = False)\n",
    "# df_covid_for_nlp_10K[['paper_id', 'topic_count_vector', 'topic_words_count_vector', 'topic_tfidf', 'topic_words_tfidf', 'cleaned_text', 'body_word_count']].to_csv(output / 'df_covid_for_nlp_10K.csv', index = False)\n",
    "\n",
    "df_covid_for_nlp_10K[['paper_id', 'topic_count_vector', 'topic_words_count_vector', 'topic_tfidf', 'topic_words_tfidf', 'body_word_count']].to_csv(output / 'df_covid_for_nlp_10K.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4644c32551fb23aa873a7738ecc8d777bd49877e    4\n",
       "72a5640aa0c307fbe171ca7ad55d3fda48b53988    4\n",
       "9ce0a6cfd53840cd985f7a1439708c7a48bb7f23    3\n",
       "f3aafdecdc43a3f57e58cf6dcea038b1834a953e    2\n",
       "58be092086c74c58e9067121a6ba4836468e7ec3    2\n",
       "                                           ..\n",
       "129341a52b43ccd59368d094950322d983ebe223    1\n",
       "88def2a04604c4a9a918c9273bfc8d336323045f    1\n",
       "92b28fb0a43d34081844407727df1dbd2474c7ab    1\n",
       "b59b58c13370a390a58c6cd79e61f97bf9bee37d    1\n",
       "4bf587d8051a33e9e8215ef96afa025a943dc1b8    1\n",
       "Name: sha, Length: 28450, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata['sha'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_license        20873\n",
       "comm_use_subset        8803\n",
       "noncomm_use_subset     2133\n",
       "biorxiv_medrxiv        1020\n",
       "Name: full_text_file, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata['full_text_file'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_text_file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biorxiv_medrxiv</th>\n",
       "      <td>885</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comm_use_subset</th>\n",
       "      <td>8695</td>\n",
       "      <td>8803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom_license</th>\n",
       "      <td>16861</td>\n",
       "      <td>20873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noncomm_use_subset</th>\n",
       "      <td>2021</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>28462</td>\n",
       "      <td>28462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sha  source_x\n",
       "full_text_file                     \n",
       "biorxiv_medrxiv       885      1020\n",
       "comm_use_subset      8695      8803\n",
       "custom_license      16861     20873\n",
       "noncomm_use_subset   2021      2133\n",
       "All                 28462     28462"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.pivot_table(df_all_sources_metadata, index='full_text_file', values='sha', aggfunc='count', margins=True)\n",
    "\n",
    "pd.pivot_table(df_all_sources_metadata, index='full_text_file', values=['sha', 'source_x'], aggfunc='count', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44220, 15)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata_with_topics = df_all_sources_metadata.copy()\n",
    "df_all_sources_metadata_with_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_sources_metadata_with_topics = df_all_sources_metadata_with_topics.merge(df_covid_for_nlp_10K[['paper_id', 'topic_count_vector', 'topic_words_count_vector', 'topic_tfidf', 'topic_words_tfidf', 'body_word_count']], how='left', left_on='sha', right_on='paper_id')\n",
    "\n",
    "df_all_sources_metadata_with_topics = df_all_sources_metadata_with_topics.merge(df_covid_for_nlp_10K, how='left', left_on='sha', right_on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id', 'license',\n",
      "       'abstract_x', 'publish_time', 'authors', 'journal',\n",
      "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
      "       'full_text_file', 'paper_id', 'abstract_y', 'body_text',\n",
      "       'abstract_word_count', 'body_word_count', 'cleaned_text',\n",
      "       'topic_count_vector', 'topic_tfidf', 'topic_number_count_vector',\n",
      "       'topic_words_count_vector', 'topic_number_tfidf', 'topic_words_tfidf'],\n",
      "      dtype='object')\n",
      "(44220, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract_x</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>...</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>topic_count_vector</th>\n",
       "      <th>topic_tfidf</th>\n",
       "      <th>topic_number_count_vector</th>\n",
       "      <th>topic_words_count_vector</th>\n",
       "      <th>topic_number_tfidf</th>\n",
       "      <th>topic_words_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Intrauterine virus infections and congenital h...</td>\n",
       "      <td>10.1016/0002-8703(72)90077-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4361535.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract The etiologic basis for the vast majo...</td>\n",
       "      <td>1972-12-31</td>\n",
       "      <td>Overall, James C.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Coronaviruses in Balkan nephritis</td>\n",
       "      <td>10.1016/0002-8703(80)90355-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6243850.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Cigarette smoking and coronary heart disease: ...</td>\n",
       "      <td>10.1016/0002-8703(80)90356-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7355701.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Friedman, Gary D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aecbc613ebdab36753235197ffb4f35734b5ca63</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Clinical and immunologic studies in identical ...</td>\n",
       "      <td>10.1016/0002-9343(73)90176-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4579077.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Middle-aged female identical twins, o...</td>\n",
       "      <td>1973-08-31</td>\n",
       "      <td>Brunner, Carolyn M.; Horwitz, David A.; Shann,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Epidemiology of community-acquired respiratory...</td>\n",
       "      <td>10.1016/0002-9343(85)90361-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4014285.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Upper respiratory tract infections ar...</td>\n",
       "      <td>1985-06-28</td>\n",
       "      <td>Garibaldi, Richard A.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sha  source_x  \\\n",
       "0                                       NaN  Elsevier   \n",
       "1                                       NaN  Elsevier   \n",
       "2                                       NaN  Elsevier   \n",
       "3  aecbc613ebdab36753235197ffb4f35734b5ca63  Elsevier   \n",
       "4                                       NaN  Elsevier   \n",
       "\n",
       "                                               title  \\\n",
       "0  Intrauterine virus infections and congenital h...   \n",
       "1                  Coronaviruses in Balkan nephritis   \n",
       "2  Cigarette smoking and coronary heart disease: ...   \n",
       "3  Clinical and immunologic studies in identical ...   \n",
       "4  Epidemiology of community-acquired respiratory...   \n",
       "\n",
       "                            doi pmcid  pubmed_id    license  \\\n",
       "0  10.1016/0002-8703(72)90077-4   NaN  4361535.0  els-covid   \n",
       "1  10.1016/0002-8703(80)90355-5   NaN  6243850.0  els-covid   \n",
       "2  10.1016/0002-8703(80)90356-7   NaN  7355701.0  els-covid   \n",
       "3  10.1016/0002-9343(73)90176-9   NaN  4579077.0  els-covid   \n",
       "4  10.1016/0002-9343(85)90361-4   NaN  4014285.0  els-covid   \n",
       "\n",
       "                                          abstract_x publish_time  \\\n",
       "0  Abstract The etiologic basis for the vast majo...   1972-12-31   \n",
       "1                                                NaN   1980-03-31   \n",
       "2                                                NaN   1980-03-31   \n",
       "3  Abstract Middle-aged female identical twins, o...   1973-08-31   \n",
       "4  Abstract Upper respiratory tract infections ar...   1985-06-28   \n",
       "\n",
       "                                             authors  ... body_text  \\\n",
       "0                                  Overall, James C.  ...       NaN   \n",
       "1  Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...  ...       NaN   \n",
       "2                                   Friedman, Gary D  ...       NaN   \n",
       "3  Brunner, Carolyn M.; Horwitz, David A.; Shann,...  ...       NaN   \n",
       "4                              Garibaldi, Richard A.  ...       NaN   \n",
       "\n",
       "   abstract_word_count body_word_count  cleaned_text topic_count_vector  \\\n",
       "0                  NaN             NaN           NaN                NaN   \n",
       "1                  NaN             NaN           NaN                NaN   \n",
       "2                  NaN             NaN           NaN                NaN   \n",
       "3                  NaN             NaN           NaN                NaN   \n",
       "4                  NaN             NaN           NaN                NaN   \n",
       "\n",
       "  topic_tfidf topic_number_count_vector topic_words_count_vector  \\\n",
       "0         NaN                       NaN                      NaN   \n",
       "1         NaN                       NaN                      NaN   \n",
       "2         NaN                       NaN                      NaN   \n",
       "3         NaN                       NaN                      NaN   \n",
       "4         NaN                       NaN                      NaN   \n",
       "\n",
       "   topic_number_tfidf  topic_words_tfidf  \n",
       "0                 NaN                NaN  \n",
       "1                 NaN                NaN  \n",
       "2                 NaN                NaN  \n",
       "3                 NaN                NaN  \n",
       "4                 NaN                NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_all_sources_metadata_with_topics.columns)\n",
    "print(df_all_sources_metadata_with_topics.shape)\n",
    "df_all_sources_metadata_with_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     34976\n",
       "35.0      590\n",
       "10.0      458\n",
       "6.0       416\n",
       "27.0      402\n",
       "25.0      382\n",
       "38.0      342\n",
       "46.0      340\n",
       "41.0      333\n",
       "30.0      328\n",
       "9.0       311\n",
       "4.0       295\n",
       "3.0       288\n",
       "8.0       243\n",
       "33.0      232\n",
       "24.0      229\n",
       "23.0      211\n",
       "45.0      211\n",
       "47.0      205\n",
       "44.0      205\n",
       "48.0      200\n",
       "5.0       195\n",
       "32.0      177\n",
       "29.0      177\n",
       "28.0      176\n",
       "7.0       175\n",
       "12.0      174\n",
       "36.0      164\n",
       "39.0      160\n",
       "22.0      157\n",
       "2.0       150\n",
       "42.0      149\n",
       "40.0      119\n",
       "15.0      118\n",
       "16.0       96\n",
       "17.0       80\n",
       "11.0       80\n",
       "20.0       71\n",
       "37.0       70\n",
       "14.0       68\n",
       "21.0       66\n",
       "19.0       61\n",
       "1.0        54\n",
       "26.0       48\n",
       "0.0        45\n",
       "49.0       43\n",
       "18.0       39\n",
       "34.0       39\n",
       "43.0       28\n",
       "13.0       22\n",
       "31.0       22\n",
       "Name: topic_count_vector, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata_with_topics['topic_count_vector'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
