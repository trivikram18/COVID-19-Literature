{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pprint\n",
    "# import ijson\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import fnmatch\n",
    "import glob\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for dirname, _, filenames in os.walk('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "\n",
    "# for filename in fnmatch.filter(filenames, '*.txt'):\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "input = Path('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge')\n",
    "output = Path('C:/Users/trivikram.cheedella/OneDrive - JD Power/Data Science Data/CORD-19-research-challenge/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sources_metadata = pd.read_csv(input / 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44220, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44220 entries, 0 to 44219\n",
      "Data columns (total 15 columns):\n",
      "sha                            28462 non-null object\n",
      "source_x                       44220 non-null object\n",
      "title                          43996 non-null object\n",
      "doi                            40750 non-null object\n",
      "pmcid                          23319 non-null object\n",
      "pubmed_id                      22943 non-null float64\n",
      "license                        44220 non-null object\n",
      "abstract                       35806 non-null object\n",
      "publish_time                   34197 non-null object\n",
      "authors                        41074 non-null object\n",
      "journal                        33173 non-null object\n",
      "Microsoft Academic Paper ID    964 non-null float64\n",
      "WHO #Covidence                 1767 non-null object\n",
      "has_full_text                  44220 non-null bool\n",
      "full_text_file                 32829 non-null object\n",
      "dtypes: bool(1), float64(2), object(12)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df_all_sources_metadata.shape)\n",
    "df_all_sources_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>full_text_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Intrauterine virus infections and congenital h...</td>\n",
       "      <td>10.1016/0002-8703(72)90077-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4361535.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract The etiologic basis for the vast majo...</td>\n",
       "      <td>1972-12-31</td>\n",
       "      <td>Overall, James C.</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Coronaviruses in Balkan nephritis</td>\n",
       "      <td>10.1016/0002-8703(80)90355-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6243850.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Georgescu, Leonida; Diosi, Peter; Bu≈£iu, Ioan;...</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Cigarette smoking and coronary heart disease: ...</td>\n",
       "      <td>10.1016/0002-8703(80)90356-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7355701.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Friedman, Gary D</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aecbc613ebdab36753235197ffb4f35734b5ca63</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Clinical and immunologic studies in identical ...</td>\n",
       "      <td>10.1016/0002-9343(73)90176-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4579077.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Middle-aged female identical twins, o...</td>\n",
       "      <td>1973-08-31</td>\n",
       "      <td>Brunner, Carolyn M.; Horwitz, David A.; Shann,...</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Epidemiology of community-acquired respiratory...</td>\n",
       "      <td>10.1016/0002-9343(85)90361-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4014285.0</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Upper respiratory tract infections ar...</td>\n",
       "      <td>1985-06-28</td>\n",
       "      <td>Garibaldi, Richard A.</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sha  source_x  \\\n",
       "0                                       NaN  Elsevier   \n",
       "1                                       NaN  Elsevier   \n",
       "2                                       NaN  Elsevier   \n",
       "3  aecbc613ebdab36753235197ffb4f35734b5ca63  Elsevier   \n",
       "4                                       NaN  Elsevier   \n",
       "\n",
       "                                               title  \\\n",
       "0  Intrauterine virus infections and congenital h...   \n",
       "1                  Coronaviruses in Balkan nephritis   \n",
       "2  Cigarette smoking and coronary heart disease: ...   \n",
       "3  Clinical and immunologic studies in identical ...   \n",
       "4  Epidemiology of community-acquired respiratory...   \n",
       "\n",
       "                            doi pmcid  pubmed_id    license  \\\n",
       "0  10.1016/0002-8703(72)90077-4   NaN  4361535.0  els-covid   \n",
       "1  10.1016/0002-8703(80)90355-5   NaN  6243850.0  els-covid   \n",
       "2  10.1016/0002-8703(80)90356-7   NaN  7355701.0  els-covid   \n",
       "3  10.1016/0002-9343(73)90176-9   NaN  4579077.0  els-covid   \n",
       "4  10.1016/0002-9343(85)90361-4   NaN  4014285.0  els-covid   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  Abstract The etiologic basis for the vast majo...   1972-12-31   \n",
       "1                                                NaN   1980-03-31   \n",
       "2                                                NaN   1980-03-31   \n",
       "3  Abstract Middle-aged female identical twins, o...   1973-08-31   \n",
       "4  Abstract Upper respiratory tract infections ar...   1985-06-28   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                  Overall, James C.   \n",
       "1  Georgescu, Leonida; Diosi, Peter; Bu≈£iu, Ioan;...   \n",
       "2                                   Friedman, Gary D   \n",
       "3  Brunner, Carolyn M.; Horwitz, David A.; Shann,...   \n",
       "4                              Garibaldi, Richard A.   \n",
       "\n",
       "                            journal  Microsoft Academic Paper ID  \\\n",
       "0            American Heart Journal                          NaN   \n",
       "1            American Heart Journal                          NaN   \n",
       "2            American Heart Journal                          NaN   \n",
       "3  The American Journal of Medicine                          NaN   \n",
       "4  The American Journal of Medicine                          NaN   \n",
       "\n",
       "  WHO #Covidence  has_full_text  full_text_file  \n",
       "0            NaN          False  custom_license  \n",
       "1            NaN          False  custom_license  \n",
       "2            NaN          False  custom_license  \n",
       "3            NaN           True  custom_license  \n",
       "4            NaN          False  custom_license  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sources_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code for reading in the JSON file is taken from ...\n",
    "\n",
    "https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 933 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29315"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_json = glob.glob(f'{input}/**/*.json', recursive=True)\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0015023cc06b5362d332b3baf348d11567ca2fbb: word count: 194 22 Text word count: 5168 23 24 25 author/funder. All rights reserved. No reuse allowed without permission. Abstract 27 The positive stranded RNA genomes of picornaviruses comprise a si... VP3, and VP0 (which is further processed to VP2 and VP4 during virus assembly) (6). The P2 64 and P3 regions encode the non-structural proteins 2B and 2C and 3A, 3B (1-3) (VPg), 3C pro and 4 structura...\n"
     ]
    }
   ],
   "source": [
    "class FileReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path) as file:\n",
    "            content = json.load(file)\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            # Abstract\n",
    "            for entry in content['abstract']:\n",
    "                self.abstract.append(entry['text'])\n",
    "            # Body text\n",
    "            for entry in content['body_text']:\n",
    "                self.body_text.append(entry['text'])\n",
    "            self.abstract = '\\n'.join(self.abstract)\n",
    "            self.body_text = '\\n'.join(self.body_text)\n",
    "            # Extend Here\n",
    "            #\n",
    "            #\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
    "first_row = FileReader(all_json[0])\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 0 of 29315\n",
      "Processing index: 2931 of 29315\n",
      "Processing index: 5862 of 29315\n",
      "Processing index: 8793 of 29315\n",
      "Processing index: 11724 of 29315\n",
      "Processing index: 14655 of 29315\n",
      "Processing index: 17586 of 29315\n",
      "Processing index: 20517 of 29315\n",
      "Processing index: 23448 of 29315\n",
      "Processing index: 26379 of 29315\n",
      "Processing index: 29310 of 29315\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>Nipah Virus (NiV) came into limelight recently...</td>\n",
       "      <td>Nipah is an infectious negative-sense single-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>Background: A novel coronavirus (2019-nCoV) em...</td>\n",
       "      <td>In December 2019, a cluster of patients with p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  Infectious bronchitis (IB) causes significant ...   \n",
       "3  Nipah Virus (NiV) came into limelight recently...   \n",
       "4  Background: A novel coronavirus (2019-nCoV) em...   \n",
       "\n",
       "                                           body_text  \n",
       "0  VP3, and VP0 (which is further processed to VP...  \n",
       "1  The 2019-nCoV epidemic has spread across China...  \n",
       "2  Infectious bronchitis (IB), which is caused by...  \n",
       "3  Nipah is an infectious negative-sense single-s...  \n",
       "4  In December 2019, a cluster of patients with p...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\n",
    "for idx, entry in enumerate(all_json):\n",
    "    if idx % (len(all_json) // 10) == 0:\n",
    "        print(f'Processing index: {idx} of {len(all_json)}')\n",
    "    content = FileReader(entry)\n",
    "    dict_['paper_id'].append(content.paper_id)\n",
    "    dict_['abstract'].append(content.abstract)\n",
    "    dict_['body_text'].append(content.body_text)\n",
    "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text'])\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across China...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Infectious bronchitis (IB) causes significant ...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>Nipah Virus (NiV) came into limelight recently...</td>\n",
       "      <td>Nipah is an infectious negative-sense single-s...</td>\n",
       "      <td>326</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>Background: A novel coronavirus (2019-nCoV) em...</td>\n",
       "      <td>In December 2019, a cluster of patients with p...</td>\n",
       "      <td>22</td>\n",
       "      <td>4642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  Infectious bronchitis (IB) causes significant ...   \n",
       "3  Nipah Virus (NiV) came into limelight recently...   \n",
       "4  Background: A novel coronavirus (2019-nCoV) em...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  VP3, and VP0 (which is further processed to VP...                  241   \n",
       "1  The 2019-nCoV epidemic has spread across China...                    0   \n",
       "2  Infectious bronchitis (IB), which is caused by...                 1647   \n",
       "3  Nipah is an infectious negative-sense single-s...                  326   \n",
       "4  In December 2019, a cluster of patients with p...                   22   \n",
       "\n",
       "   body_word_count  \n",
       "0             1728  \n",
       "1              755  \n",
       "2             4003  \n",
       "3             2399  \n",
       "4             4642  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_covid['abstract_word_count'] = df_covid['abstract'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid['body_word_count'] = df_covid['body_text'].apply(lambda x: len(x.strip().split()))\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>abstract_word_count</th>\n",
       "      <th>body_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>word count: 194 22 text word count: 5168 23 24...</td>\n",
       "      <td>vp3, and vp0 (which is further processed to vp...</td>\n",
       "      <td>241</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td></td>\n",
       "      <td>the 2019-ncov epidemic has spread across china...</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>infectious bronchitis (ib) causes significant ...</td>\n",
       "      <td>infectious bronchitis (ib), which is caused by...</td>\n",
       "      <td>1647</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0139ea4ca580af99b602c6435368e7fdbefacb03</td>\n",
       "      <td>nipah virus (niv) came into limelight recently...</td>\n",
       "      <td>nipah is an infectious negative-sense single-s...</td>\n",
       "      <td>326</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>013d9d1cba8a54d5d3718c229b812d7cf91b6c89</td>\n",
       "      <td>background: a novel coronavirus (2019-ncov) em...</td>\n",
       "      <td>in december 2019, a cluster of patients with p...</td>\n",
       "      <td>22</td>\n",
       "      <td>4642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "2  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "3  0139ea4ca580af99b602c6435368e7fdbefacb03   \n",
       "4  013d9d1cba8a54d5d3718c229b812d7cf91b6c89   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 text word count: 5168 23 24...   \n",
       "1                                                      \n",
       "2  infectious bronchitis (ib) causes significant ...   \n",
       "3  nipah virus (niv) came into limelight recently...   \n",
       "4  background: a novel coronavirus (2019-ncov) em...   \n",
       "\n",
       "                                           body_text  abstract_word_count  \\\n",
       "0  vp3, and vp0 (which is further processed to vp...                  241   \n",
       "1  the 2019-ncov epidemic has spread across china...                    0   \n",
       "2  infectious bronchitis (ib), which is caused by...                 1647   \n",
       "3  nipah is an infectious negative-sense single-s...                  326   \n",
       "4  in december 2019, a cluster of patients with p...                   22   \n",
       "\n",
       "   body_word_count  \n",
       "0             1728  \n",
       "1              755  \n",
       "2             4003  \n",
       "3             2399  \n",
       "4             4642  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(lambda x: x.lower())\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(lambda x: x.lower())\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <td>29315</td>\n",
       "      <td>29315</td>\n",
       "      <td>ac81102667b0d56edeb8ab0044765dc49a19f374</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>29315</td>\n",
       "      <td>21049</td>\n",
       "      <td></td>\n",
       "      <td>8051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_text</th>\n",
       "      <td>29315</td>\n",
       "      <td>29117</td>\n",
       "      <td>in previous reports, workers have characterize...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_word_count</th>\n",
       "      <td>29315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.501</td>\n",
       "      <td>175.353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>240</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_word_count</th>\n",
       "      <td>29315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4802.29</td>\n",
       "      <td>7322.71</td>\n",
       "      <td>1</td>\n",
       "      <td>2444</td>\n",
       "      <td>3730</td>\n",
       "      <td>5509.5</td>\n",
       "      <td>260378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique  \\\n",
       "paper_id             29315  29315   \n",
       "abstract             29315  21049   \n",
       "body_text            29315  29117   \n",
       "abstract_word_count  29315    NaN   \n",
       "body_word_count      29315    NaN   \n",
       "\n",
       "                                                                   top  freq  \\\n",
       "paper_id                      ac81102667b0d56edeb8ab0044765dc49a19f374     1   \n",
       "abstract                                                                8051   \n",
       "body_text            in previous reports, workers have characterize...     4   \n",
       "abstract_word_count                                                NaN   NaN   \n",
       "body_word_count                                                    NaN   NaN   \n",
       "\n",
       "                        mean      std  min   25%   50%     75%     max  \n",
       "paper_id                 NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "abstract                 NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "body_text                NaN      NaN  NaN   NaN   NaN     NaN     NaN  \n",
       "abstract_word_count  164.501  175.353    0     0   161     240    4767  \n",
       "body_word_count      4802.29  7322.71    1  2444  3730  5509.5  260378  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>ac81102667b0d56edeb8ab0044765dc49a19f374</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>29117</td>\n",
       "      <td>21044</td>\n",
       "      <td></td>\n",
       "      <td>8004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_text</th>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>multiple sclerosis (ms) is an inflammatory dem...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_word_count</th>\n",
       "      <td>29117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.504</td>\n",
       "      <td>175.637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_word_count</th>\n",
       "      <td>29117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4811.94</td>\n",
       "      <td>7344.37</td>\n",
       "      <td>1</td>\n",
       "      <td>2450</td>\n",
       "      <td>3733</td>\n",
       "      <td>5513</td>\n",
       "      <td>260378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique  \\\n",
       "paper_id             29117  29117   \n",
       "abstract             29117  21044   \n",
       "body_text            29117  29117   \n",
       "abstract_word_count  29117    NaN   \n",
       "body_word_count      29117    NaN   \n",
       "\n",
       "                                                                   top  freq  \\\n",
       "paper_id                      ac81102667b0d56edeb8ab0044765dc49a19f374     1   \n",
       "abstract                                                                8004   \n",
       "body_text            multiple sclerosis (ms) is an inflammatory dem...     1   \n",
       "abstract_word_count                                                NaN   NaN   \n",
       "body_word_count                                                    NaN   NaN   \n",
       "\n",
       "                        mean      std  min   25%   50%   75%     max  \n",
       "paper_id                 NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "abstract                 NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "body_text                NaN      NaN  NaN   NaN   NaN   NaN     NaN  \n",
       "abstract_word_count  164.504  175.637    0     0   160   240    4767  \n",
       "body_word_count      4811.94  7344.37    1  2450  3733  5513  260378  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid.drop_duplicates(['body_text'], inplace=True)\n",
    "df_covid.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwrods from STOPWORDS:  190\n",
      "Number of stopwrods from stopwords.words('english'):  179\n",
      "Number of stopwrods from custom_stopwords:  263\n",
      "['so', 'they', 'just', \"she's\", \"i'd\", 'she', 'than', 'too', 'doing', \"mightn't\", \"we'll\", 'theirs', 'have', 'do', \"how's\", 'were', \"doesn't\", 'all', 'both', 'into', 'her', \"didn't\", \"they'd\", 'over', 'nor', 'been', 'yourself', \"you'll\", 'about', 'how', 'other', \"can't\", 'from', 'could', 'however', 'until', 'through', 'before', 'in', 'o', \"where's\", \"don't\", 'against', 'isn', 'hers', \"won't\", 'would', \"you'd\", 'shouldn', \"shan't\", 'aren', 'com', 'his', 'am', 'had', 'shan', 'an', \"you're\", 'such', 'it', 'which', 'be', 've', 'like', \"isn't\", 'further', \"you've\", 'didn', 'its', 'while', \"we'd\", 'this', 'www', 'their', 'is', 'above', 'then', 's', \"that'll\", \"mustn't\", 'there', 'any', \"couldn't\", 'now', 'after', 'me', 'very', 'why', 'we', \"aren't\", 'haven', 'ain', \"should've\", 'that', \"he's\", 'our', 'also', 'yourselves', 'else', 'ever', 'otherwise', \"what's\", 'whom', 'mustn', 'ourselves', 'won', 'has', 'with', \"it's\", 'on', 'wouldn', 'the', 'itself', 'only', 'hasn', \"we've\", 'my', 'ma', 'each', 're', 'being', \"they'll\", 'between', \"when's\", 'these', 'ours', 'will', \"i've\", 'own', \"he'd\", 'down', 'if', 'under', 'll', 'wasn', \"he'll\", 'your', 'no', 'or', 'y', 'some', \"weren't\", \"who's\", 'below', 'herself', 'when', 'cannot', 'doesn', 'did', \"there's\", \"why's\", 'does', 'of', 'couldn', 'he', 'yours', \"shouldn't\", 'himself', 'here', 'are', 'off', 'more', 'those', 'but', 'few', 'him', 'k', 'same', \"she'd\", 'a', 'as', \"wouldn't\", 'having', 'since', 'mightn', \"she'll\", 'i', 'http', 'during', 'to', \"here's\", \"i'll\", 'once', 'not', 'don', 'm', 'what', 'd', 'weren', 'r', 'shall', 'you', 'and', 't', \"hasn't\", \"hadn't\", 'themselves', \"let's\", 'get', 'up', \"wasn't\", 'for', 'where', \"that's\", \"they've\", 'most', 'needn', 'hadn', 'should', \"haven't\", \"needn't\", 'by', \"we're\", 'them', 'ought', \"they're\", 'because', 'who', 'was', 'can', \"i'm\", 'again', 'myself', 'at', 'out', 'q', 'license', 'preprint', 'copyright', 'http', 'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', 'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da', 'dell', 'non', 'si']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"Number of stopwrods from STOPWORDS: \", len(STOPWORDS))\n",
    "print(\"Number of stopwrods from stopwords.words('english'): \", len(stopwords.words('english')))\n",
    "other_stopwords = ['q', 'license', 'preprint', 'copyright', 'http', 'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', 'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si']\n",
    "custom_stopwords = []\n",
    "custom_stopwords = list(set(stopwords.words('english') + list(STOPWORDS))) + other_stopwords\n",
    "\n",
    "print(\"Number of stopwrods from custom_stopwords: \", len(custom_stopwords))\n",
    "print(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_stopword_tokens(tokens, tolower=False):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    remove_punc = [word for word in tokens if word not in string.punctuation]\n",
    "    if tolower:\n",
    "        return [word.lower() for word in remove_punc if word.lower() not in custom_stopwords]\n",
    "    else:\n",
    "        return [word for word in remove_punc if word not in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_stopword_text(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    remove_punc = [word for word in text if word not in string.punctuation]\n",
    "    remove_punc = ''.join(remove_punc)\n",
    "    return [word.lower() for word in remove_punc.split() if word.lower() not in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_the_text(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        remove_punc = [word for word in tokens if word not in string.punctuation]\n",
    "        remove_stopwords = [word.lower() for word in remove_punc if word.lower() not in custom_stopwords]\n",
    "        more_than_three = [w for w in remove_stopwords if len(w)>3]\n",
    "        lem = [lemmatizer.lemmatize(w) for w in more_than_three]\n",
    "        return ' '.join(lem)\n",
    "\n",
    "# cleaned_text = clean_the_text(\"my name is TRIVIKRAM, and I am first born in my fam don't process processing patients\")\n",
    "# print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_for_nlp = df_covid.copy()\n",
    "df_covid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_covid_for_nlp['cleaned_text'] = df_covid_for_nlp['body_text'].apply(lambda x: clean_the_text(x))\n",
    "# print(cleaned_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    processed virus assembly region encode non-str...\n",
       "1    2019-ncov epidemic spread across china country...\n",
       "2    infectious bronchitis caused infectious bronch...\n",
       "3    nipah infectious negative-sense single-strande...\n",
       "4    december 2019 cluster patient pneumonia unknow...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_for_nlp_10K = df_covid_for_nlp.head(10000)\n",
    "df_covid_for_nlp_10K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(df_covid_for_nlp_10K['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x110226 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7517951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=50, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=50, random_state=42, n_jobs=-1)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peif2a\n",
      "islk\n",
      "collections\n",
      "pbmsf7c\n",
      "fab\n",
      "glioma\n",
      "bioinformation\n",
      "machine\n",
      "toning\n",
      "ck04\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106325,  96144,  76161,  86412, 105990,  53255, 106475,  23334,\n",
       "        63943,  82451], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viral\n",
      "structure\n",
      "pcv2\n",
      "replication\n",
      "vesicle\n",
      "infected\n",
      "virus\n",
      "cell\n",
      "membrane\n",
      "prrsv\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['viral', 'structure', 'pcv2', 'replication', 'vesicle', 'infected', 'virus', 'cell', 'membrane', 'prrsv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['stem', 'ribosome', 'frame', 'trna', 'frameshifting', 'sequence', 'translation', 'site', 'mrna', 'codon']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['cell', 'genome', 'interaction', 'ifitm3', 'host', 'replication', 'domain', 'viral', 'virus', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['method', 'positive', 'probe', 'reaction', 'pcr', 'rt', 'detection', 'primer', 'assay', 'sample']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['host', 'immune', 'activation', 'ifn', 'type', 'protein', 'response', 'viral', 'virus', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['protein', 'vector', 'human', 'immune', 'virus', 'antigen', 'antibody', 'response', 'cell', 'vaccine']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['anti', 'immune', 'level', 'macrophage', 'response', 'cytokine', 'expression', 'mouse', 'il', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['coronaviruses', 'hcov', 'coronavirus', 'camel', 'bat', 'virus', 'human', 'sars', 'mers', 'cov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['protein', 'acid', 'amino', 'genome', 'codon', 'isolates', 'mutation', 'sequence', 'gene', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['ebov', 'effect', 'inhibitor', 'viral', 'treated', 'protein', 'virus', 'entry', 'infected', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #10:\n",
      "['sample', 'case', 'clinical', 'pneumonia', 'pathogen', 'viral', 'patient', 'virus', 'child', 'respiratory']\n",
      "\n",
      "\n",
      "Top 10 words for topic #11:\n",
      "['sequencing', 'hadv', 'community', 'microbiota', 'microbial', 'specie', 'pathogen', 'bacteria', 'bacterial', 'sample']\n",
      "\n",
      "\n",
      "Top 10 words for topic #12:\n",
      "['replication', 'control', 'viral', 'culture', 'level', 'gene', 'virus', 'infected', 'expression', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #13:\n",
      "['mouse', 'cell', 'ifn', 'gondii', 'gene', 'stat1', 'expression', 'infected', 'cov', 'sars']\n",
      "\n",
      "\n",
      "Top 10 words for topic #14:\n",
      "['day', 'allergic', 'clinical', 'symptom', 'effect', 'subject', 'trial', 'group', 'asthma', 'treatment']\n",
      "\n",
      "\n",
      "Top 10 words for topic #15:\n",
      "['control', 'intestinal', 'astrocyte', 'calf', 'microglia', 'animal', 'neuron', 'group', 'mouse', 'brain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #16:\n",
      "['2013', '2011', 'treatment', 'target', '2012', 'antiviral', 'compound', 'activity', 'effect', 'drug']\n",
      "\n",
      "\n",
      "Top 10 words for topic #17:\n",
      "['virus', 'aptamers', 'pdcov', 'farm', 'porcine', 'swine', 'tgev', 'piglet', 'pig', 'pedv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #18:\n",
      "['compared', 'immune', 'control', 'challenge', 'level', 'response', 'vaccinated', 'vaccine', 'vaccination', 'group']\n",
      "\n",
      "\n",
      "Top 10 words for topic #19:\n",
      "['cc', '1101', 'doi', 'funder', 'org', '10', 'reviewed', 'author', 'peer', 'holder']\n",
      "\n",
      "\n",
      "Top 10 words for topic #20:\n",
      "['formation', 'pathway', 'viral', 'replication', 'lipid', 'membrane', 'stress', 'cell', 'protein', 'autophagy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #21:\n",
      "['rna', 'ifit1', 'stable', 'yeast', 'cell', 'mrna', 'expression', 'strain', 'reference', 'gene']\n",
      "\n",
      "\n",
      "Top 10 words for topic #22:\n",
      "['expression', 'network', 'lncrnas', 'function', 'peptide', 'mass', 'sample', 'identified', 'ms', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #23:\n",
      "['farm', 'wild', 'transmission', 'population', 'disease', 'pathogen', 'human', 'host', 'specie', 'animal']\n",
      "\n",
      "\n",
      "Top 10 words for topic #24:\n",
      "['level', 'associated', 'identified', 'expressed', 'pathway', 'response', 'transcript', 'table', 'expression', 'gene']\n",
      "\n",
      "\n",
      "Top 10 words for topic #25:\n",
      "['mortality', 'associated', 'level', 'blood', 'treatment', 'group', 'clinical', 'severe', 'disease', 'patient']\n",
      "\n",
      "\n",
      "Top 10 words for topic #26:\n",
      "['ncov', '2019', 'level', '5p', 'target', 'expression', 'cell', 'mirna', 'mirnas', 'mir']\n",
      "\n",
      "\n",
      "Top 10 words for topic #27:\n",
      "['group', 'reported', 'year', 'medical', 'risk', 'health', 'participant', 'care', 'patient', 'hospital']\n",
      "\n",
      "\n",
      "Top 10 words for topic #28:\n",
      "['treatment', 'level', 'anti', 'induced', 'expression', 'effect', 'tumor', 'activity', 'cancer', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #29:\n",
      "['solution', 'detection', 'phage', 'image', 'sample', 'method', 'temperature', 'concentration', 'surface', 'particle']\n",
      "\n",
      "\n",
      "Top 10 words for topic #30:\n",
      "['virus', 'domain', 'transfected', 'viral', 'expression', 'plasmid', 'binding', 'mutant', 'cell', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #31:\n",
      "['genetic', 'population', 'sequence', 'position', 'allele', 'rabv', 'strain', 'rabies', 'rvfv', 'variant']\n",
      "\n",
      "\n",
      "Top 10 words for topic #32:\n",
      "['patient', 'year', 'surveillance', '2009', 'respiratory', 'case', 'pandemic', 'h1n1', 'virus', 'influenza']\n",
      "\n",
      "\n",
      "Top 10 words for topic #33:\n",
      "['contact', 'parameter', 'epidemic', 'network', 'disease', 'transmission', 'rate', 'population', 'individual', 'model']\n",
      "\n",
      "\n",
      "Top 10 words for topic #34:\n",
      "['infected', 'zika', 'viral', 'flavivirus', 'chikv', 'mosquito', 'virus', 'dengue', 'denv', 'zikv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #35:\n",
      "['global', 'response', 'information', 'surveillance', 'outbreak', 'research', 'country', 'public', 'disease', 'health']\n",
      "\n",
      "\n",
      "Top 10 words for topic #36:\n",
      "['week', 'period', 'temperature', 'factor', 'risk', 'incidence', 'year', 'disease', 'case', 'cat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #37:\n",
      "['inhibitor', 'active', 'site', 'residue', 'catalytic', 'rdrp', 'protease', 'enzyme', 'substrate', 'activity']\n",
      "\n",
      "\n",
      "Top 10 words for topic #38:\n",
      "['covid', 'period', '19', 'china', 'day', 'medrxiv', 'transmission', 'epidemic', 'outbreak', 'case']\n",
      "\n",
      "\n",
      "Top 10 words for topic #39:\n",
      "['identity', 'specie', 'detected', 'region', 'positive', 'virus', 'genotype', 'strain', 'sample', 'sequence']\n",
      "\n",
      "\n",
      "Top 10 words for topic #40:\n",
      "['containing', 'fraction', 'cell', 'antibody', 'buffer', 'plant', 'expression', 'recombinant', 'purified', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #41:\n",
      "['antigen', 'group', 'virus', 'response', 'specific', 'anti', 'serum', 'cell', 'mouse', 'antibody']\n",
      "\n",
      "\n",
      "Top 10 words for topic #42:\n",
      "['receptor', 'membrane', 'residue', 'cell', 'protein', 'fusion', 'epitope', 'binding', 'hiv', 'peptide']\n",
      "\n",
      "\n",
      "Top 10 words for topic #43:\n",
      "['ang', 'adam17', 'small', 'apelin', 'target', 'domain', 'activity', 'sp', 'protein', 'ace2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #44:\n",
      "['cell', 'observed', 'disease', 'model', 'group', 'infected', 'tissue', 'animal', 'mouse', 'lung']\n",
      "\n",
      "\n",
      "Top 10 words for topic #45:\n",
      "['activity', 'complex', 'interaction', 'acid', 'protein', 'site', 'compound', 'residue', 'binding', 'structure']\n",
      "\n",
      "\n",
      "Top 10 words for topic #46:\n",
      "['region', 'host', 'human', 'specie', 'sequencing', 'read', 'viral', 'genome', 'sequence', 'virus']\n",
      "\n",
      "\n",
      "Top 10 words for topic #47:\n",
      "['algorithm', 'distribution', 'approach', 'distance', 'sequence', 'information', 'cluster', 'value', 'model', 'method']\n",
      "\n",
      "\n",
      "Top 10 words for topic #48:\n",
      "['assay', 'medium', 'concentration', 'titer', 'replication', 'ml', 'culture', 'viral', 'cell', 'virus']\n",
      "\n",
      "\n",
      "Top 10 words for topic #49:\n",
      "['infected', 'duck', 'mouse', 'strain', 'poultry', 'avian', 'bird', 'h5n1', 'chicken', 'virus']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = tfidf_vect.fit_transform(df_covid_for_nlp_10K['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x110226 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7517951 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=50, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=50, random_state=42)\n",
    "nmf.fit(doc_term_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pomp\n",
      "survey\n",
      "pparg\n",
      "m19921\n",
      "26k\n",
      "verdinexor\n",
      "annelid\n",
      "ethoxy\n",
      "craniata\n",
      "drago\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(tfidf_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lncrna\n",
      "3p\n",
      "sirna\n",
      "mrna\n",
      "5p\n",
      "lncrnas\n",
      "ev71\n",
      "mirna\n",
      "mirnas\n",
      "mir\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['lncrna', '3p', 'sirna', 'mrna', '5p', 'lncrnas', 'ev71', 'mirna', 'mirnas', 'mir']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['diagnosis', 'care', 'severe', 'respiratory', 'treatment', 'clinical', 'pneumonia', 'admission', 'hospital', 'patient']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['10', 'reuse', 'author', 'org', 'doi', 'funder', '1101', 'peer', 'holder', 'reviewed']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['amino', 'isolates', 'recombination', 'genotype', 'nucleotide', 'phylogenetic', 'tree', 'genome', 'strain', 'sequence']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['rbd', 'east', 'korea', 'hdpp4', 'human', 'arabia', 'saudi', 'dpp4', 'cov', 'mers']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['probability', 'simulation', 'value', 'individual', 'estimate', 'rate', 'population', 'parameter', 'epidemic', 'model']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['orf3', 'vero', 'feed', 'diarrhea', 'farm', 'cv777', 'strain', 'pig', 'piglet', 'pedv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['particle', 'genome', 'antiviral', 'infected', 'respiratory', 'human', 'replication', 'host', 'viral', 'virus']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['replication', 'domain', 'ms', 'cellular', 'virion', 'viral', 'host', 'interaction', 'membrane', 'protein']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['national', 'emergency', 'outbreak', 'policy', 'global', 'disease', 'surveillance', 'country', 'public', 'health']\n",
      "\n",
      "\n",
      "Top 10 words for topic #10:\n",
      "['trial', 'immunity', 'vaccinated', 'immunization', 'vector', 'immune', 'antigen', 'response', 'vaccination', 'vaccine']\n",
      "\n",
      "\n",
      "Top 10 words for topic #11:\n",
      "['template', 'sensitivity', 'isothermal', 'detection', 'assay', 'amplification', 'reaction', 'primer', 'rt', 'lamp']\n",
      "\n",
      "\n",
      "Top 10 words for topic #12:\n",
      "['vero', 'pregnant', 'mosquito', 'ediii', 'microcephaly', 'mr766', '2016', 'zika', 'flavivirus', 'zikv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #13:\n",
      "['virus', 'h3n2', 'seasonal', 'season', '2009', 'sari', 'surveillance', 'h1n1', 'pandemic', 'influenza']\n",
      "\n",
      "\n",
      "Top 10 words for topic #14:\n",
      "['bacterial', 'infant', 'pathogen', 'year', 'pneumoniae', 'pneumonia', 'hmpv', 'hbov', 'respiratory', 'child']\n",
      "\n",
      "\n",
      "Top 10 words for topic #15:\n",
      "['nc', 'cc', 'wuhan', 'display', '19', 'granted', '2020', 'perpetuity', 'covid', 'medrxiv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #16:\n",
      "['2003', 'civet', 'covid', '2020', 'spike', 'coronavirus', 'coronaviruses', 'covs', 'cov', 'sars']\n",
      "\n",
      "\n",
      "Top 10 words for topic #17:\n",
      "['tumor', 'apoptosis', 'ml', 'anti', 'line', 'medium', 'culture', 'infected', 'expression', 'cell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #18:\n",
      "['myotis', 'cave', 'rabies', 'human', 'host', 'fruit', 'reservoir', 'covs', 'specie', 'bat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #19:\n",
      "['10', '1Œ≤', 'immune', 'response', 'tnf', 'macrophage', 'cell', 'inflammatory', 'cytokine', 'il']\n",
      "\n",
      "\n",
      "Top 10 words for topic #20:\n",
      "['amplification', 'sensitivity', 'specimen', 'rt', 'primer', 'pcr', 'probe', 'detection', 'assay', 'sample']\n",
      "\n",
      "\n",
      "Top 10 words for topic #21:\n",
      "['coronavirus', 'genotype', 'coronaviruses', 'respiratory', 'hcovs', 'hku1', '229e', 'oc43', 'nl63', 'hcov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #22:\n",
      "['inhibition', 'extract', 'treatment', 'effect', 'inhibitor', 'concentration', 'antiviral', 'activity', 'drug', 'compound']\n",
      "\n",
      "\n",
      "Top 10 words for topic #23:\n",
      "['fcovs', 'fiv', 'fecv', 'dog', 'shelter', 'fipv', 'feline', 'felv', 'fcov', 'cat']\n",
      "\n",
      "\n",
      "Top 10 words for topic #24:\n",
      "['pams', 'swine', 'porcine', 'nsp11', 'pcv2', 'prrs', '145', 'marc', 'pig', 'prrsv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #25:\n",
      "['wildlife', 'population', 'risk', 'zoonotic', 'specie', 'animal', 'human', 'host', 'disease', 'pathogen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #26:\n",
      "['hubei', 'market', 'coronavirus', 'city', 'china', 'january', 'wuhan', '2020', '2019', 'ncov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #27:\n",
      "['viral', 'coverage', 'assembly', 'library', 'contigs', 'sample', 'sequence', 'genome', 'sequencing', 'read']\n",
      "\n",
      "\n",
      "Top 10 words for topic #28:\n",
      "['differentially', 'expressed', 'response', 'microarray', 'regulated', 'reference', 'pathway', 'transcript', 'expression', 'gene']\n",
      "\n",
      "\n",
      "Top 10 words for topic #29:\n",
      "['hpai', 'flock', 'strain', 'duck', 'avian', 'h5n1', 'h7n9', 'poultry', 'bird', 'chicken']\n",
      "\n",
      "\n",
      "Top 10 words for topic #30:\n",
      "['day', 'neutrophil', 'weight', 'group', 'infected', 'tissue', 'brain', 'animal', 'lung', 'mouse']\n",
      "\n",
      "\n",
      "Top 10 words for topic #31:\n",
      "['denv1', 'fever', 'denv2', 'serotype', 'serotypes', 'flavivirus', 'genotype', 'mosquito', 'dengue', 'denv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #32:\n",
      "['cardiac', 'kidney', 'ards', 'spike', 'lung', 'expression', 'angiotensin', 'receptor', 'ang', 'ace2']\n",
      "\n",
      "\n",
      "Top 10 words for topic #33:\n",
      "['symptom', 'contact', 'day', 'period', 'travel', 'onset', 'estimate', 'transmission', 'outbreak', 'case']\n",
      "\n",
      "\n",
      "Top 10 words for topic #34:\n",
      "['ebolavirus', 'vp40', 'entry', 'fusion', 'npc1', 'marv', 'ebola', 'filovirus', 'gp', 'ebov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #35:\n",
      "['membrane', 'rs12252', 'entry', 'fusion', 'ifitm2', 'ifitms', 'hiv', 'ifitm1', 'ifitm', 'ifitm3']\n",
      "\n",
      "\n",
      "Top 10 words for topic #36:\n",
      "['immune', 'type', 'activation', 'antiviral', 'ifns', 'cell', 'signaling', 'rig', 'response', 'ifn']\n",
      "\n",
      "\n",
      "Top 10 words for topic #37:\n",
      "['fiber', 'respiratory', 'outbreak', 'pneumonia', '55', 'hadvs', 'china', 'adenovirus', 'hexon', 'hadv']\n",
      "\n",
      "\n",
      "Top 10 words for topic #38:\n",
      "['diarrhea', 'dairy', 'piglet', 'pig', 'cattle', 'brsv', 'animal', 'farm', 'herd', 'calf']\n",
      "\n",
      "\n",
      "Top 10 words for topic #39:\n",
      "['residue', 'cell', 'class', 'allele', 'protein', 'sequence', 'prediction', 'hla', 'epitope', 'peptide']\n",
      "\n",
      "\n",
      "Top 10 words for topic #40:\n",
      "['scfv', 'epitope', 'anti', 'phage', 'antigen', 'elisa', 'serum', 'neutralizing', 'mabs', 'antibody']\n",
      "\n",
      "\n",
      "Top 10 words for topic #41:\n",
      "['cell', 'vesicle', 'atg5', 'autophagosome', 'replication', 'autophagosomes', 'membrane', 'autophagic', 'lc3', 'autophagy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #42:\n",
      "['tracing', 'probability', 'degree', 'household', 'edge', 'transmission', 'individual', 'node', 'contact', 'network']\n",
      "\n",
      "\n",
      "Top 10 words for topic #43:\n",
      "['mutation', 'fusion', 'loop', 'interaction', 'mutant', 'site', 'domain', 'binding', 'structure', 'residue']\n",
      "\n",
      "\n",
      "Top 10 words for topic #44:\n",
      "['ribosome', 'mrna', 'translation', 'trna', 'rscu', 'bias', 'frameshifting', 'synonymous', 'usage', 'codon']\n",
      "\n",
      "\n",
      "Top 10 words for topic #45:\n",
      "['deltacoronavirus', 'swine', 'intestinal', 'china', 'porcine', 'diarrhea', 'pig', 'piglet', 'tgev', 'pdcov']\n",
      "\n",
      "\n",
      "Top 10 words for topic #46:\n",
      "['milk', 'kenya', 'human', 'egypt', 'cov', 'seroprevalence', 'bactrian', 'herd', 'dromedary', 'camel']\n",
      "\n",
      "\n",
      "Top 10 words for topic #47:\n",
      "['wheezing', 'rhinovirus', 'respiratory', 'asthmatic', 'lung', 'airway', 'copd', 'exacerbation', 'hrv', 'asthma']\n",
      "\n",
      "\n",
      "Top 10 words for topic #48:\n",
      "['attitude', 'perception', 'perceived', 'questionnaire', 'pandemic', 'survey', 'risk', 'respondent', 'hcws', 'participant']\n",
      "\n",
      "\n",
      "Top 10 words for topic #49:\n",
      "['albopictus', 'e2', 'chik', 'replication', 'chikf', 'mosquito', 'nsp3', 'alphavirus', 'nsp2', 'chikv']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_values = nmf.transform(doc_term_matrix)\n",
    "# reviews_datasets['Topic'] = topic_values.argmax(axis=1)\n",
    "# reviews_datasets.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
